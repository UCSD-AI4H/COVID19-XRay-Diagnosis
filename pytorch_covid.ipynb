{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python \n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import torchxrayvision as xrv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                        xrv.datasets.XRayResizer(224)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARDS': {0.0: 88, 1.0: 4},\n",
      " 'Bacterial Pneumonia': {0.0: 86, 1.0: 6},\n",
      " 'COVID-19': {0.0: 23, 1.0: 69},\n",
      " 'MERS': {0.0: 92},\n",
      " 'No Finding': {0.0: 91, 1.0: 1},\n",
      " 'Pneumonia': {0.0: 2, 1.0: 90},\n",
      " 'SARS': {0.0: 81, 1.0: 11},\n",
      " 'Streptococcus': {0.0: 86, 1.0: 6},\n",
      " 'Viral Pneumonia': {0.0: 12, 1.0: 80}}\n",
      "Covid Chest x-ray stats dataset stats:\n",
      "\n",
      "COVID19_Dataset num_samples=92,\n",
      "number of training=73, ,\n",
      " number of testing=19\n"
     ]
    }
   ],
   "source": [
    "covid19 = xrv.datasets.COVID19_Dataset(\n",
    "            imgpath='covid_data/images',\n",
    "            csvpath='covid_data/metadata.csv',\n",
    "            transform=transform)\n",
    "\n",
    "# count split sizes\n",
    "n_train = int(0.8 * len(covid19))\n",
    "# n_valid_test = len(covid19) - n_train\n",
    "# n_valid = int(0.5 * n_valid_test)\n",
    "# n_test = n_valid_test - n_valid\n",
    "n_test = len(covid19) - n_train\n",
    "\n",
    "# print(f'Covid Chest x-ray stats dataset stats:\\n\\n{covid19},\\nnumber of training={n_train}, \\\n",
    "# \\n number of validing={n_valid} ,\\n number of testing={n_test}',flush=True)\n",
    "print(f'Covid Chest x-ray stats dataset stats:\\n\\n{covid19},\\nnumber of training={n_train}, \\\n",
    ",\\n number of testing={n_test}',flush=True)\n",
    "# split the dataset\n",
    "# train_set, val_set, test_set = torch.utils.data.random_split(covid19, [n_train, n_valid, n_test])\n",
    "train_set, test_set = torch.utils.data.random_split(covid19, [n_train, n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = bs, num_workers = 0, shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "def load_val_data():\n",
    "    test_loader = torch.utils.data.DataLoader(val_set, batch_size = bs, num_workers = 0, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "def load_test_data():\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size = bs, num_workers = 0, shuffle=False)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_data = xrv.datasets.COVID19_Dataset('covid_data/images', transform=transform)\n",
    "# # print(train_data[1][\"PA\"])\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, num_workers = 0, shuffle=True)\n",
    "# for idx, batch_samples in enumerate(train_loader):\n",
    "#     print(1)\n",
    "#     print(idx)\n",
    "#     text_batchs, text_labels = batch_samples[\"PA\"], batch_samples[\"lab\"]\n",
    "#     print(text_batchs)\n",
    "# # dataiter=iter(train_loader)\n",
    "# # print(dataiter)\n",
    "# # data=dataiter.next\n",
    "# # print(data[\"PA\"])\n",
    "\n",
    "# # images=data\n",
    "# # print(data)\n",
    "# # print(type(images),type(labels))\n",
    "# # print(type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNetModel(\n",
      "  (dense_net): DenseNet(\n",
      "    (features): Sequential(\n",
      "      (conv0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu0): ReLU(inplace=True)\n",
      "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (denseblock1): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition1): _Transition(\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock2): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition2): _Transition(\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock3): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition3): _Transition(\n",
      "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock4): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DenseNetModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Pass in parsed HyperOptArgumentParser to the model\n",
    "        :param hparams:\n",
    "        \"\"\"\n",
    "        super(DenseNetModel, self).__init__()\n",
    "\n",
    "        self.dense_net = xrv.models.DenseNet(num_classes=2)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.dense_net(x)\n",
    "        return logits\n",
    "    \n",
    "model = DenseNetModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()           \n",
    "            \n",
    "#         self.conv1 = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
    "#         self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "#         self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(0.5)        \n",
    "#         self.activation = nn.RReLU(inplace = True)\n",
    "        \n",
    "#         self.pool = nn.AdaptiveAvgPool2d((6,6))\n",
    "        \n",
    "#         self.dense1 = nn.Linear(256*6*6, 4096)\n",
    "#         self.dense2 = nn.Linear(4096, 4096)\n",
    "#         self.out = nn.Linear(4096, 2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.activation(x)\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride = 2)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.activation(x)\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride = 2)\n",
    "        \n",
    "#         x = self.conv3(x)\n",
    "#         x = self.activation(x)\n",
    "        \n",
    "#         x = self.conv4(x)\n",
    "#         x = self.activation(x)\n",
    "        \n",
    "#         x = self.conv5(x)\n",
    "#         x = self.activation(x)\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride = 2)\n",
    "        \n",
    "#         ########\n",
    "        \n",
    "#         x = self.pool(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "        \n",
    "#         x = self.dropout(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.activation(x)\n",
    "        \n",
    "\n",
    "#         x = self.dropout(x) \n",
    "#         x = self.dense2(x)\n",
    "#         x = self.activation(x)\n",
    "#         x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    train_loader = load_train_data()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = batch_samples[\"PA\"].to(device), batch_samples[\"lab\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "#         print(output)\n",
    "#         print(target.long()[:, 2])\n",
    "#         loss = nn.functional.nll_loss(output, target.long()[:, 2])\n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long()[:, 2])\n",
    "        train_loss += criteria(output, target.long()[:, 2])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long()[:, 2].view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_index, len(train_loader),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\n",
    "            \n",
    "#             niter = epoch*len(train_loader)+batch_index\n",
    "#             writer.add_scalar('Train/Loss', loss.data, niter)\n",
    "    \n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_loader = load_test_data()\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            \n",
    "            data, target = batch_samples[\"PA\"].to(device), batch_samples[\"lab\"].to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            test_loss += criteria(output, target.long()[:, 2])\n",
    "#             test_loss += F.nll_loss(output, target.long()[:, 2], reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print(pred)\n",
    "#             print(target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long()[:, 2].view_as(pred)).sum().item()\n",
    "#             print(pred.eq(target.long()[:, 2].view_as(pred)))\n",
    "            TP += ((pred == 1) & (target.long()[:, 2].view_as(pred).data == 1)).cpu().sum()\n",
    "            TN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "#             # FN    predict 0 label 1\n",
    "            FN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 1)).cpu().sum()\n",
    "#             # FP    predict 1 label 0\n",
    "            FP += ((pred == 1) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "            print(TP,TN,FN,FP)\n",
    "            \n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long()[:, 2].cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "#             print('pred',predlist)\n",
    "# #             print('pred2',pred)\n",
    "#             print('target',targetlist)\n",
    "            \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP.item() / (TP + FP).item()\n",
    "        print('precision',p)\n",
    "        p = TP.item() / (TP + FP).item()\n",
    "        r = TP.item() / (TP + FN).item()\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN).item() / (TP + TN + FP + FN).item()\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "#         print('pred',predlist)\n",
    "#         print('target',targetlist)\n",
    "#         print('pred',predcpu)\n",
    "#         print('target',targetcpu)\n",
    "#         print('AUC',roc_auc_score(targetcpu,predcpu))\n",
    "        print('AUC',roc_auc_score(targetlist,predlist))\n",
    "#         try:\n",
    "#             print('AUC',roc_auc_score(predlist, targetlist))\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "#         tpr = tp/(tp+fn)\n",
    "#         fpr = fp/(fp+tn)\n",
    "#         tpr_list.append(tpr)\n",
    "#         fpr_list.append(fpr)\n",
    "#         fpr=TP.item() / (FP + TN).item()\n",
    "#         tpr_list.append(r)\n",
    "#         fpr_list.append(fpr)\n",
    "#         print('AUC',np.trapz(tpr_list, fpr_list))\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "\n",
    "    # Display results\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100.0 * correct / len(test_loader.dataset)))\n",
    "    \n",
    "#     return (100.0 * correct / len(test_loader.dataset))\n",
    "    \n",
    "    # Write to tensorboard\n",
    "#     writer.add_scalar('Test Accuracy', 100.0 * correct / len(test_loader.dataset), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    \"\"\"Model modified.\n",
    "\n",
    "    The architecture of our model is the same as standard DenseNet121\n",
    "    except the classifier layer which has an additional sigmoid function.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, out_size):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n",
    "        num_ftrs = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint\n",
      "=> loaded checkpoint\n",
      "DenseNet121(\n",
      "  (densenet121): DenseNet(\n",
      "    (features): Sequential(\n",
      "      (conv0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu0): ReLU(inplace=True)\n",
      "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (denseblock1): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition1): _Transition(\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock2): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition2): _Transition(\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock3): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition3): _Transition(\n",
      "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (denseblock4): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model define\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# Tensorboard Writer\n",
    "\n",
    "CKPT_PATH = 'model.pth.tar'\n",
    "N_CLASSES = 14\n",
    "\n",
    "DenseNet121 = DenseNet121(N_CLASSES).cuda()\n",
    "# model = CNN().to(device)\n",
    "# model = DenseNetModel().to(device)\n",
    "\n",
    "\n",
    "CKPT_PATH = './CheXNet/model.pth.tar'\n",
    "\n",
    "if os.path.isfile(CKPT_PATH):\n",
    "    print(\"=> loading checkpoint\")\n",
    "    checkpoint = torch.load(CKPT_PATH)        \n",
    "    state_dict = checkpoint['state_dict']\n",
    "    remove_data_parallel = False\n",
    "\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "    for key in list(state_dict.keys()):\n",
    "        match = pattern.match(key)\n",
    "        new_key = match.group(1) + match.group(2) if match else key\n",
    "        new_key = new_key[7:] if remove_data_parallel else new_key\n",
    "        new_key = new_key[7:]\n",
    "        state_dict[new_key] = state_dict[key]\n",
    "        del state_dict[key]\n",
    "\n",
    "\n",
    "    DenseNet121.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded checkpoint\")\n",
    "#     print(densenet121)\n",
    "else:\n",
    "    print(\"=> no checkpoint found\")\n",
    "    \n",
    "DenseNet121.densenet121.classifier._modules['0'] = nn.Linear(in_features=1024, out_features=2, bias=True)\n",
    "DenseNet121.densenet121.features.conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "print(DenseNet121)\n",
    "model = DenseNet121.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5615, 0.4898],\n",
      "        [0.0128, 0.9891],\n",
      "        [0.1224, 0.8897],\n",
      "        [0.0184, 0.9858]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 1 [0/19 (0%)]\tTrain Loss: 0.122438\n",
      "tensor([[0.0053, 0.9953],\n",
      "        [0.8502, 0.1584],\n",
      "        [0.0382, 0.9744],\n",
      "        [0.0818, 0.9259]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0851, 0.9156],\n",
      "        [0.1429, 0.8757],\n",
      "        [0.8181, 0.1952],\n",
      "        [0.0021, 0.9987]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0443, 0.9590],\n",
      "        [0.1591, 0.8669],\n",
      "        [0.0658, 0.9458],\n",
      "        [0.0775, 0.9312]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0147, 0.9865],\n",
      "        [0.7179, 0.3077],\n",
      "        [0.0463, 0.9544],\n",
      "        [0.0427, 0.9691]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.9481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 1 [4/19 (21%)]\tTrain Loss: 0.186228\n",
      "tensor([[0.0295, 0.9703],\n",
      "        [0.0056, 0.9967],\n",
      "        [0.9186, 0.0883],\n",
      "        [0.0286, 0.9714]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[5.2947e-03, 9.9606e-01],\n",
      "        [7.0539e-04, 9.9950e-01],\n",
      "        [5.9792e-01, 4.0141e-01],\n",
      "        [9.2328e-01, 7.6870e-02]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.6953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9419, 0.0556],\n",
      "        [0.0043, 0.9969],\n",
      "        [0.0038, 0.9970],\n",
      "        [0.1268, 0.8944]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.8089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.1861e-01, 1.9659e-01],\n",
      "        [4.2681e-02, 9.6698e-01],\n",
      "        [7.4662e-01, 2.7233e-01],\n",
      "        [3.8349e-04, 9.9968e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.5089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 1 [8/19 (42%)]\tTrain Loss: 0.131707\n",
      "tensor([[0.0450, 0.9677],\n",
      "        [0.1318, 0.8761],\n",
      "        [0.1193, 0.8923],\n",
      "        [0.0306, 0.9723]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0985, 0.9061],\n",
      "        [0.0716, 0.9451],\n",
      "        [0.0324, 0.9769],\n",
      "        [0.1465, 0.8564]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0902, 0.9180],\n",
      "        [0.0601, 0.9422],\n",
      "        [0.0013, 0.9992],\n",
      "        [0.8299, 0.1737]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0480, 0.9572],\n",
      "        [0.9260, 0.0797],\n",
      "        [0.0181, 0.9825],\n",
      "        [0.0050, 0.9964]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 1 [12/19 (63%)]\tTrain Loss: 0.104529\n",
      "tensor([[0.0266, 0.9757],\n",
      "        [0.1291, 0.8729],\n",
      "        [0.0128, 0.9909],\n",
      "        [0.3618, 0.6746]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[9.0831e-05, 9.9995e-01],\n",
      "        [5.6212e-01, 4.0879e-01],\n",
      "        [6.8484e-01, 3.3089e-01],\n",
      "        [3.7738e-01, 5.9769e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.5685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.2288, 0.8121],\n",
      "        [0.0264, 0.9774],\n",
      "        [0.0232, 0.9766],\n",
      "        [0.1607, 0.8774]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.1782, 0.8437],\n",
      "        [0.8532, 0.1463],\n",
      "        [0.0011, 0.9991],\n",
      "        [0.0156, 0.9875]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.5290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 1 [16/19 (84%)]\tTrain Loss: 0.139571\n",
      "tensor([[8.0069e-01, 1.9810e-01],\n",
      "        [8.9277e-04, 9.9931e-01],\n",
      "        [3.5199e-03, 9.9783e-01],\n",
      "        [8.1677e-01, 1.6644e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0561, 0.9508]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1429, Accuracy: 55/73 (75%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(4) tensor(0) tensor(0)\n",
      "tensor(7) tensor(4) tensor(1) tensor(0)\n",
      "tensor(11) tensor(4) tensor(1) tensor(0)\n",
      "tensor(14) tensor(4) tensor(1) tensor(0)\n",
      "TP= tensor(14) TN= tensor(4) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(14)\n",
      "precision 1.0\n",
      "recall 0.9333333333333333\n",
      "F1 0.9655172413793104\n",
      "acc 0.9473684210526315\n",
      "AUC 0.95\n",
      "\n",
      "Test set: Average loss: 0.1101, Accuracy: 18/19 (95%)\n",
      "\n",
      "tensor([[0.3982, 0.5896],\n",
      "        [0.0161, 0.9865],\n",
      "        [0.1339, 0.8784],\n",
      "        [0.0163, 0.9876]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 2 [0/19 (0%)]\tTrain Loss: 0.102062\n",
      "tensor([[0.0062, 0.9945],\n",
      "        [0.0012, 0.9993],\n",
      "        [0.9126, 0.0908],\n",
      "        [0.4054, 0.6081]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0122, 0.9886],\n",
      "        [0.5385, 0.5036],\n",
      "        [0.0153, 0.9874],\n",
      "        [0.0476, 0.9572]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9475, 0.0553],\n",
      "        [0.0191, 0.9836],\n",
      "        [0.0027, 0.9979],\n",
      "        [0.0148, 0.9866]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.6118, 0.3783],\n",
      "        [0.0364, 0.9750],\n",
      "        [0.0036, 0.9972],\n",
      "        [0.1141, 0.8938]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.5964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 2 [4/19 (21%)]\tTrain Loss: 0.154146\n",
      "tensor([[0.8758, 0.1246],\n",
      "        [0.0016, 0.9990],\n",
      "        [0.1475, 0.8679],\n",
      "        [0.0190, 0.9813]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.5957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0550, 0.9530],\n",
      "        [0.0742, 0.9318],\n",
      "        [0.0199, 0.9879],\n",
      "        [0.1537, 0.8103]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9473, 0.0594],\n",
      "        [0.0093, 0.9931],\n",
      "        [0.0188, 0.9815],\n",
      "        [0.0058, 0.9953]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0243, 0.9787],\n",
      "        [0.0434, 0.9617],\n",
      "        [0.0550, 0.9530],\n",
      "        [0.1660, 0.8487]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 2 [8/19 (42%)]\tTrain Loss: 0.088268\n",
      "tensor([[0.8045, 0.2068],\n",
      "        [0.0023, 0.9979],\n",
      "        [0.8505, 0.1557],\n",
      "        [0.0013, 0.9992]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7905, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1279, 0.8948],\n",
      "        [0.0226, 0.9801],\n",
      "        [0.0561, 0.9464],\n",
      "        [0.0617, 0.9433]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.3205, 0.7046],\n",
      "        [0.0238, 0.9786],\n",
      "        [0.2130, 0.8330],\n",
      "        [0.0059, 0.9947]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.8403, 0.1647],\n",
      "        [0.0019, 0.9983],\n",
      "        [0.8146, 0.1802],\n",
      "        [0.0010, 0.9993]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 2 [12/19 (63%)]\tTrain Loss: 0.097239\n",
      "tensor([[0.0031, 0.9968],\n",
      "        [0.0353, 0.9718],\n",
      "        [0.6540, 0.3901],\n",
      "        [0.1366, 0.8804]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.6530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[7.4879e-01, 2.5762e-01],\n",
      "        [6.5732e-01, 3.3422e-01],\n",
      "        [1.2295e-02, 9.9027e-01],\n",
      "        [4.4572e-04, 9.9971e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9308, 0.0712],\n",
      "        [0.0035, 0.9975],\n",
      "        [0.0056, 0.9956],\n",
      "        [0.0644, 0.9349]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0070, 0.9954],\n",
      "        [0.0132, 0.9845],\n",
      "        [0.5672, 0.4793],\n",
      "        [0.0788, 0.9275]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.9229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 2 [16/19 (84%)]\tTrain Loss: 0.183661\n",
      "tensor([[0.1328, 0.9046],\n",
      "        [0.0061, 0.9945],\n",
      "        [0.0298, 0.9715],\n",
      "        [0.3092, 0.7028]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0555, 0.9534]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "criterion tensor(1.2396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1378, Accuracy: 59/73 (81%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(0) tensor(1)\n",
      "tensor(8) tensor(3) tensor(0) tensor(1)\n",
      "tensor(12) tensor(3) tensor(0) tensor(1)\n",
      "tensor(15) tensor(3) tensor(0) tensor(1)\n",
      "TP= tensor(15) TN= tensor(3) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(16)\n",
      "precision 0.9375\n",
      "recall 1.0\n",
      "F1 0.967741935483871\n",
      "acc 0.9473684210526315\n",
      "AUC 0.9833333333333334\n",
      "\n",
      "Test set: Average loss: 0.1068, Accuracy: 18/19 (95%)\n",
      "\n",
      "tensor([[0.0039, 0.9966],\n",
      "        [0.8986, 0.1240],\n",
      "        [0.2084, 0.7626],\n",
      "        [0.0022, 0.9985]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 3 [0/19 (0%)]\tTrain Loss: 0.130017\n",
      "tensor([[0.0089, 0.9925],\n",
      "        [0.0107, 0.9925],\n",
      "        [0.0151, 0.9823],\n",
      "        [0.9297, 0.0766]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.2254e-01, 1.8544e-01],\n",
      "        [5.0069e-05, 9.9997e-01],\n",
      "        [3.1441e-01, 6.8826e-01],\n",
      "        [6.5191e-01, 3.4163e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.5463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[3.5621e-04, 9.9978e-01],\n",
      "        [8.5380e-01, 1.3806e-01],\n",
      "        [5.7799e-01, 4.2434e-01],\n",
      "        [1.7408e-02, 9.8421e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.4132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.1455, 0.8807],\n",
      "        [0.0171, 0.9875],\n",
      "        [0.0463, 0.9532],\n",
      "        [0.0821, 0.9206]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 3 [4/19 (21%)]\tTrain Loss: 0.088214\n",
      "tensor([[0.0136, 0.9875],\n",
      "        [0.0128, 0.9899],\n",
      "        [0.9158, 0.0902],\n",
      "        [0.0224, 0.9828]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.6855, 0.3443],\n",
      "        [0.0091, 0.9920],\n",
      "        [0.0211, 0.9830],\n",
      "        [0.0238, 0.9771]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9089, 0.0871],\n",
      "        [0.0016, 0.9989],\n",
      "        [0.0295, 0.9742],\n",
      "        [0.0334, 0.9701]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.7132, 0.2864],\n",
      "        [0.0011, 0.9993],\n",
      "        [0.8935, 0.1082],\n",
      "        [0.0019, 0.9983]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 3 [8/19 (42%)]\tTrain Loss: 0.094124\n",
      "tensor([[0.0123, 0.9897],\n",
      "        [0.0576, 0.9442],\n",
      "        [0.0264, 0.9773],\n",
      "        [0.3105, 0.7273]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0244, 0.9803],\n",
      "        [0.0107, 0.9905],\n",
      "        [0.0026, 0.9979],\n",
      "        [0.9413, 0.0628]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.2137, 0.7839],\n",
      "        [0.0306, 0.9800],\n",
      "        [0.0177, 0.9824],\n",
      "        [0.0880, 0.9219]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0115, 0.9921],\n",
      "        [0.9371, 0.0651],\n",
      "        [0.0015, 0.9987],\n",
      "        [0.0623, 0.9353]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 3 [12/19 (63%)]\tTrain Loss: 0.083180\n",
      "tensor([[0.0073, 0.9943],\n",
      "        [0.0057, 0.9942],\n",
      "        [0.0271, 0.9785],\n",
      "        [0.9314, 0.0739]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.1763e-02, 9.2328e-01],\n",
      "        [8.3521e-01, 1.5336e-01],\n",
      "        [5.1570e-01, 4.9580e-01],\n",
      "        [1.3307e-04, 9.9992e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.6910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0512, 0.9546],\n",
      "        [0.0040, 0.9970],\n",
      "        [0.9314, 0.0685],\n",
      "        [0.0067, 0.9946]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.1473, 0.8929],\n",
      "        [0.0244, 0.9770],\n",
      "        [0.0498, 0.9481],\n",
      "        [0.0555, 0.9581]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 3 [16/19 (84%)]\tTrain Loss: 0.087286\n",
      "tensor([[0.0213, 0.9807],\n",
      "        [0.0033, 0.9971],\n",
      "        [0.9199, 0.0834],\n",
      "        [0.0198, 0.9867]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0521, 0.9548]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1060, Accuracy: 68/73 (93%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(4) tensor(0) tensor(0)\n",
      "tensor(8) tensor(4) tensor(0) tensor(0)\n",
      "tensor(12) tensor(4) tensor(0) tensor(0)\n",
      "tensor(15) tensor(4) tensor(0) tensor(0)\n",
      "TP= tensor(15) TN= tensor(4) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(15)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 1.0\n",
      "\n",
      "Test set: Average loss: 0.1012, Accuracy: 19/19 (100%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0367, 0.9767],\n",
      "        [0.1347, 0.8615],\n",
      "        [0.0272, 0.9726],\n",
      "        [0.0713, 0.9329]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 4 [0/19 (0%)]\tTrain Loss: 0.087798\n",
      "tensor([[0.1033, 0.9043],\n",
      "        [0.7775, 0.2413],\n",
      "        [0.0063, 0.9953],\n",
      "        [0.0071, 0.9942]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0186, 0.9853],\n",
      "        [0.0669, 0.9380],\n",
      "        [0.2158, 0.8236],\n",
      "        [0.0294, 0.9704]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0120, 0.9885],\n",
      "        [0.2632, 0.8136],\n",
      "        [0.0273, 0.9755],\n",
      "        [0.0814, 0.9103]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0019, 0.9986],\n",
      "        [0.0156, 0.9866],\n",
      "        [0.0217, 0.9813],\n",
      "        [0.9493, 0.0533]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 4 [4/19 (21%)]\tTrain Loss: 0.081366\n",
      "tensor([[0.0076, 0.9943],\n",
      "        [0.0138, 0.9885],\n",
      "        [0.9541, 0.0525],\n",
      "        [0.0048, 0.9953]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.1082, 0.9144],\n",
      "        [0.0310, 0.9732],\n",
      "        [0.0734, 0.9244],\n",
      "        [0.0509, 0.9546]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0334, 0.9724],\n",
      "        [0.0514, 0.9534],\n",
      "        [0.0554, 0.9526],\n",
      "        [0.0720, 0.9297]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[7.6296e-01, 2.2834e-01],\n",
      "        [3.6820e-03, 9.9731e-01],\n",
      "        [7.8837e-01, 2.2315e-01],\n",
      "        [4.8879e-04, 9.9964e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 4 [8/19 (42%)]\tTrain Loss: 0.115230\n",
      "tensor([[9.2035e-01, 8.3391e-02],\n",
      "        [2.6142e-03, 9.9784e-01],\n",
      "        [6.8804e-01, 3.1995e-01],\n",
      "        [3.3599e-04, 9.9976e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[9.0258e-01, 9.8089e-02],\n",
      "        [2.4478e-04, 9.9980e-01],\n",
      "        [4.3458e-01, 5.7782e-01],\n",
      "        [9.9700e-03, 9.9243e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.6519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0294, 0.9769],\n",
      "        [0.0014, 0.9989],\n",
      "        [0.0099, 0.9912],\n",
      "        [0.9510, 0.0505]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0046, 0.9963],\n",
      "        [0.9490, 0.0537],\n",
      "        [0.0071, 0.9939],\n",
      "        [0.0166, 0.9857]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 4 [12/19 (63%)]\tTrain Loss: 0.081029\n",
      "tensor([[0.0057, 0.9958],\n",
      "        [0.0323, 0.9722],\n",
      "        [0.0173, 0.9833],\n",
      "        [0.8568, 0.1436]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[9.2701e-01, 7.3545e-02],\n",
      "        [6.7796e-01, 3.0569e-01],\n",
      "        [3.6029e-04, 9.9976e-01],\n",
      "        [2.3835e-03, 9.9794e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[3.1069e-04, 9.9978e-01],\n",
      "        [6.6256e-03, 9.9413e-01],\n",
      "        [7.5105e-01, 2.7016e-01],\n",
      "        [7.9838e-01, 2.0206e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0028, 0.9975],\n",
      "        [0.9051, 0.1042],\n",
      "        [0.0114, 0.9904],\n",
      "        [0.0478, 0.9613]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 4 [16/19 (84%)]\tTrain Loss: 0.138513\n",
      "tensor([[0.9048, 0.1026],\n",
      "        [0.0106, 0.9917],\n",
      "        [0.0105, 0.9918],\n",
      "        [0.0063, 0.9932]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0465, 0.9596]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "criterion tensor(1.2505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1401, Accuracy: 59/73 (81%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(2) tensor(0) tensor(2)\n",
      "tensor(8) tensor(2) tensor(0) tensor(2)\n",
      "tensor(12) tensor(2) tensor(0) tensor(2)\n",
      "tensor(15) tensor(2) tensor(0) tensor(2)\n",
      "TP= tensor(15) TN= tensor(2) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(17)\n",
      "precision 0.8823529411764706\n",
      "recall 1.0\n",
      "F1 0.9375\n",
      "acc 0.8947368421052632\n",
      "AUC 1.0\n",
      "\n",
      "Test set: Average loss: 0.1116, Accuracy: 17/19 (89%)\n",
      "\n",
      "tensor([[8.5633e-01, 1.6024e-01],\n",
      "        [7.1921e-01, 2.6066e-01],\n",
      "        [3.7754e-04, 9.9975e-01],\n",
      "        [3.4388e-03, 9.9675e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 5 [0/19 (0%)]\tTrain Loss: 0.095182\n",
      "tensor([[0.0036, 0.9970],\n",
      "        [0.9446, 0.0585],\n",
      "        [0.0242, 0.9786],\n",
      "        [0.0070, 0.9938]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.7306e-01, 1.3000e-01],\n",
      "        [9.1216e-04, 9.9932e-01],\n",
      "        [8.7022e-01, 1.2213e-01],\n",
      "        [5.9478e-04, 9.9956e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0221, 0.9788],\n",
      "        [0.0354, 0.9716],\n",
      "        [0.8799, 0.1243],\n",
      "        [0.0031, 0.9974]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9376, 0.0647],\n",
      "        [0.0085, 0.9936],\n",
      "        [0.0015, 0.9987],\n",
      "        [0.0606, 0.9414]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 5 [4/19 (21%)]\tTrain Loss: 0.082945\n",
      "tensor([[0.0273, 0.9777],\n",
      "        [0.5035, 0.5109],\n",
      "        [0.0281, 0.9773],\n",
      "        [0.0130, 0.9882]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0384, 0.9620],\n",
      "        [0.1567, 0.8704],\n",
      "        [0.0409, 0.9685],\n",
      "        [0.0223, 0.9783]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[4.0290e-04, 9.9974e-01],\n",
      "        [8.2993e-01, 1.6858e-01],\n",
      "        [1.6637e-03, 9.9853e-01],\n",
      "        [8.9706e-01, 1.0045e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(1.2175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[9.6374e-01, 3.6449e-02],\n",
      "        [2.4788e-02, 9.7248e-01],\n",
      "        [6.7503e-04, 9.9952e-01],\n",
      "        [1.7731e-02, 9.8546e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 5 [8/19 (42%)]\tTrain Loss: 0.101332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0669, 0.9348],\n",
      "        [0.1356, 0.8839],\n",
      "        [0.0029, 0.9974],\n",
      "        [0.1823, 0.8463]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.3402, 0.6760],\n",
      "        [0.0137, 0.9884],\n",
      "        [0.0150, 0.9871],\n",
      "        [0.0662, 0.9439]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.8687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0116, 0.9899],\n",
      "        [0.9689, 0.0331],\n",
      "        [0.0066, 0.9936],\n",
      "        [0.0019, 0.9985]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0060, 0.9958],\n",
      "        [0.0033, 0.9970],\n",
      "        [0.0264, 0.9740],\n",
      "        [0.9543, 0.0528]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 5 [12/19 (63%)]\tTrain Loss: 0.111085\n",
      "tensor([[0.0604, 0.9424],\n",
      "        [0.0019, 0.9986],\n",
      "        [0.1397, 0.8603],\n",
      "        [0.5535, 0.4775]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.6084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0054, 0.9961],\n",
      "        [0.3714, 0.6136],\n",
      "        [0.0835, 0.9239],\n",
      "        [0.0527, 0.9524]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[1.4763e-01, 8.6326e-01],\n",
      "        [1.3023e-02, 9.8860e-01],\n",
      "        [8.3750e-04, 9.9940e-01],\n",
      "        [8.4038e-01, 1.6197e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0103, 0.9901],\n",
      "        [0.0549, 0.9519],\n",
      "        [0.0172, 0.9869],\n",
      "        [0.3323, 0.7029]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 5 [16/19 (84%)]\tTrain Loss: 0.094198\n",
      "tensor([[7.1528e-02, 9.3576e-01],\n",
      "        [1.8092e-04, 9.9989e-01],\n",
      "        [9.2947e-01, 6.9743e-02],\n",
      "        [1.0653e-01, 8.8408e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.5434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0444, 0.9608]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1357, Accuracy: 59/73 (81%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(2) tensor(0) tensor(2)\n",
      "tensor(7) tensor(2) tensor(1) tensor(2)\n",
      "tensor(11) tensor(2) tensor(1) tensor(2)\n",
      "tensor(14) tensor(2) tensor(1) tensor(2)\n",
      "TP= tensor(14) TN= tensor(2) FN= tensor(1) FP= tensor(2)\n",
      "TP+FP tensor(16)\n",
      "precision 0.875\n",
      "recall 0.9333333333333333\n",
      "F1 0.9032258064516129\n",
      "acc 0.8421052631578947\n",
      "AUC 0.9333333333333333\n",
      "\n",
      "Test set: Average loss: 0.1184, Accuracy: 16/19 (84%)\n",
      "\n",
      "tensor([[8.8968e-01, 1.1122e-01],\n",
      "        [5.1711e-04, 9.9960e-01],\n",
      "        [7.6119e-04, 9.9946e-01],\n",
      "        [8.3613e-01, 1.5260e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 6 [0/19 (0%)]\tTrain Loss: 0.088352\n",
      "tensor([[0.0156, 0.9849],\n",
      "        [0.0038, 0.9969],\n",
      "        [0.1398, 0.8802],\n",
      "        [0.4901, 0.5290]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[3.2965e-04, 9.9972e-01],\n",
      "        [6.7368e-01, 3.1134e-01],\n",
      "        [7.3061e-01, 2.8755e-01],\n",
      "        [2.5977e-02, 9.7771e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.5066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.2603, 0.7613],\n",
      "        [0.0141, 0.9870],\n",
      "        [0.0977, 0.9092],\n",
      "        [0.0216, 0.9832]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0050, 0.9955],\n",
      "        [0.0070, 0.9944],\n",
      "        [0.9320, 0.0694],\n",
      "        [0.0353, 0.9681]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 6 [4/19 (21%)]\tTrain Loss: 0.101700\n",
      "tensor([[0.9485, 0.0503],\n",
      "        [0.0211, 0.9814],\n",
      "        [0.0026, 0.9978],\n",
      "        [0.0052, 0.9959]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[7.9066e-01, 2.0195e-01],\n",
      "        [5.4053e-04, 9.9956e-01],\n",
      "        [4.6813e-03, 9.9641e-01],\n",
      "        [7.1743e-01, 2.7256e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.4645, 0.5562],\n",
      "        [0.0086, 0.9932],\n",
      "        [0.0073, 0.9933],\n",
      "        [0.1264, 0.8805]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.1069e-04, 9.9931e-01],\n",
      "        [4.9030e-01, 5.4809e-01],\n",
      "        [4.3399e-01, 5.9086e-01],\n",
      "        [1.2059e-02, 9.8911e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 6 [8/19 (42%)]\tTrain Loss: 0.126426\n",
      "tensor([[0.0044, 0.9967],\n",
      "        [0.0050, 0.9955],\n",
      "        [0.9379, 0.0608],\n",
      "        [0.0146, 0.9870]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.5680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.1698, 0.8360],\n",
      "        [0.0568, 0.9578],\n",
      "        [0.0055, 0.9947],\n",
      "        [0.0364, 0.9682]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9628, 0.0390],\n",
      "        [0.0310, 0.9715],\n",
      "        [0.0055, 0.9953],\n",
      "        [0.0013, 0.9990]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[1.1145e-05, 9.9999e-01],\n",
      "        [6.2527e-01, 3.6396e-01],\n",
      "        [1.8252e-01, 8.0875e-01],\n",
      "        [8.6195e-01, 1.3146e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.5830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 6 [12/19 (63%)]\tTrain Loss: 0.145746\n",
      "tensor([[0.0086, 0.9922],\n",
      "        [0.9626, 0.0383],\n",
      "        [0.0041, 0.9972],\n",
      "        [0.0050, 0.9952]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0317, 0.9718],\n",
      "        [0.0239, 0.9790],\n",
      "        [0.0360, 0.9684],\n",
      "        [0.1085, 0.8999]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0165, 0.9856],\n",
      "        [0.0054, 0.9946],\n",
      "        [0.0034, 0.9975],\n",
      "        [0.9539, 0.0493]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[3.5733e-02, 9.6644e-01],\n",
      "        [8.9405e-03, 9.9281e-01],\n",
      "        [8.8785e-04, 9.9928e-01],\n",
      "        [9.5117e-01, 4.8035e-02]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.8014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 6 [16/19 (84%)]\tTrain Loss: 0.085264\n",
      "tensor([[8.4491e-01, 1.5360e-01],\n",
      "        [5.3439e-04, 9.9962e-01],\n",
      "        [8.7070e-01, 1.2532e-01],\n",
      "        [7.8787e-04, 9.9933e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3554, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0399, 0.9640]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1405, Accuracy: 57/73 (78%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(1) tensor(0) tensor(3)\n",
      "tensor(7) tensor(1) tensor(1) tensor(3)\n",
      "tensor(11) tensor(1) tensor(1) tensor(3)\n",
      "tensor(14) tensor(1) tensor(1) tensor(3)\n",
      "TP= tensor(14) TN= tensor(1) FN= tensor(1) FP= tensor(3)\n",
      "TP+FP tensor(17)\n",
      "precision 0.8235294117647058\n",
      "recall 0.9333333333333333\n",
      "F1 0.8749999999999999\n",
      "acc 0.7894736842105263\n",
      "AUC 0.8833333333333333\n",
      "\n",
      "Test set: Average loss: 0.1263, Accuracy: 15/19 (79%)\n",
      "\n",
      "tensor([[0.1050, 0.9108],\n",
      "        [0.0439, 0.9635],\n",
      "        [0.0150, 0.9844],\n",
      "        [0.0344, 0.9703]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 7 [0/19 (0%)]\tTrain Loss: 0.084831\n",
      "tensor([[4.9269e-01, 5.1127e-01],\n",
      "        [9.1060e-01, 9.9238e-02],\n",
      "        [1.2408e-04, 9.9990e-01],\n",
      "        [1.2029e-02, 9.9002e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.6655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9529, 0.0485],\n",
      "        [0.0017, 0.9988],\n",
      "        [0.0135, 0.9877],\n",
      "        [0.0077, 0.9929]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0142, 0.9882],\n",
      "        [0.0101, 0.9914],\n",
      "        [0.2514, 0.7412],\n",
      "        [0.0370, 0.9678]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0802, 0.9286],\n",
      "        [0.0192, 0.9846],\n",
      "        [0.0244, 0.9779],\n",
      "        [0.0466, 0.9540]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 7 [4/19 (21%)]\tTrain Loss: 0.084001\n",
      "tensor([[0.1224, 0.8897],\n",
      "        [0.0200, 0.9816],\n",
      "        [0.0529, 0.9519],\n",
      "        [0.0239, 0.9780]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9551, 0.0431],\n",
      "        [0.0022, 0.9985],\n",
      "        [0.0090, 0.9922],\n",
      "        [0.0070, 0.9928]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9598, 0.0400],\n",
      "        [0.0040, 0.9968],\n",
      "        [0.0031, 0.9975],\n",
      "        [0.0078, 0.9928]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0128, 0.9884],\n",
      "        [0.9517, 0.0491],\n",
      "        [0.0039, 0.9966],\n",
      "        [0.0034, 0.9970]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 7 [8/19 (42%)]\tTrain Loss: 0.096797\n",
      "tensor([[0.0133, 0.9888],\n",
      "        [0.0253, 0.9763],\n",
      "        [0.9426, 0.0584],\n",
      "        [0.0015, 0.9988]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0358, 0.9733],\n",
      "        [0.0499, 0.9428],\n",
      "        [0.0746, 0.9185],\n",
      "        [0.0119, 0.9912]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0074, 0.9939],\n",
      "        [0.0023, 0.9980],\n",
      "        [0.9525, 0.0453],\n",
      "        [0.0071, 0.9941]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[6.0179e-01, 4.0392e-01],\n",
      "        [1.6891e-02, 9.8370e-01],\n",
      "        [6.6086e-05, 9.9995e-01],\n",
      "        [8.6816e-01, 1.3516e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.6485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 7 [12/19 (63%)]\tTrain Loss: 0.162785\n",
      "tensor([[0.0026, 0.9979],\n",
      "        [0.0046, 0.9961],\n",
      "        [0.9453, 0.0518],\n",
      "        [0.0088, 0.9922]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[4.9545e-04, 9.9962e-01],\n",
      "        [8.9413e-01, 1.0031e-01],\n",
      "        [8.3990e-01, 1.5882e-01],\n",
      "        [3.6408e-04, 9.9973e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.8906, 0.1067],\n",
      "        [0.0132, 0.9877],\n",
      "        [0.0028, 0.9976],\n",
      "        [0.0094, 0.9927]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.2053, 0.8251],\n",
      "        [0.0077, 0.9921],\n",
      "        [0.1039, 0.9102],\n",
      "        [0.0077, 0.9926]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.5136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 7 [16/19 (84%)]\tTrain Loss: 0.132892\n",
      "tensor([[0.0276, 0.9761],\n",
      "        [0.8853, 0.1091],\n",
      "        [0.0024, 0.9974],\n",
      "        [0.0081, 0.9947]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0360, 0.9676]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1296, Accuracy: 60/73 (82%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(0) tensor(2)\n",
      "tensor(7) tensor(2) tensor(1) tensor(2)\n",
      "tensor(11) tensor(2) tensor(1) tensor(2)\n",
      "tensor(14) tensor(2) tensor(1) tensor(2)\n",
      "TP= tensor(14) TN= tensor(2) FN= tensor(1) FP= tensor(2)\n",
      "TP+FP tensor(16)\n",
      "precision 0.875\n",
      "recall 0.9333333333333333\n",
      "F1 0.9032258064516129\n",
      "acc 0.8421052631578947\n",
      "AUC 0.9\n",
      "\n",
      "Test set: Average loss: 0.1223, Accuracy: 16/19 (84%)\n",
      "\n",
      "tensor([[8.6409e-01, 1.2760e-01],\n",
      "        [8.6553e-01, 1.3103e-01],\n",
      "        [1.6104e-04, 9.9989e-01],\n",
      "        [8.1064e-04, 9.9936e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 8 [0/19 (0%)]\tTrain Loss: 0.105822\n",
      "tensor([[0.0040, 0.9968],\n",
      "        [0.0085, 0.9928],\n",
      "        [0.9017, 0.1051],\n",
      "        [0.0140, 0.9865]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0206, 0.9830],\n",
      "        [0.0062, 0.9943],\n",
      "        [0.2398, 0.7634],\n",
      "        [0.0342, 0.9717]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[4.3979e-04, 9.9969e-01],\n",
      "        [8.8524e-01, 1.1349e-01],\n",
      "        [8.6579e-01, 1.2858e-01],\n",
      "        [4.5885e-04, 9.9962e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.1594, 0.8451],\n",
      "        [0.0175, 0.9813],\n",
      "        [0.2644, 0.7446],\n",
      "        [0.0030, 0.9980]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 8 [4/19 (21%)]\tTrain Loss: 0.095457\n",
      "tensor([[0.0051, 0.9952],\n",
      "        [0.0547, 0.9594],\n",
      "        [0.0460, 0.9510],\n",
      "        [0.1096, 0.8975]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0411, 0.9592],\n",
      "        [0.0185, 0.9839],\n",
      "        [0.0228, 0.9815],\n",
      "        [0.0687, 0.9353]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3335, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0041, 0.9968],\n",
      "        [0.0035, 0.9968],\n",
      "        [0.9424, 0.0596],\n",
      "        [0.0250, 0.9770]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0070, 0.9939],\n",
      "        [0.9247, 0.0740],\n",
      "        [0.0119, 0.9894],\n",
      "        [0.0033, 0.9974]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 8 [8/19 (42%)]\tTrain Loss: 0.102144\n",
      "tensor([[5.7848e-01, 4.1373e-01],\n",
      "        [1.6123e-05, 9.9999e-01],\n",
      "        [5.0324e-01, 4.8955e-01],\n",
      "        [3.9098e-01, 6.1615e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.6099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[9.1449e-01, 8.0131e-02],\n",
      "        [2.7061e-02, 9.7644e-01],\n",
      "        [1.6005e-02, 9.8577e-01],\n",
      "        [5.3324e-04, 9.9962e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0069, 0.9941],\n",
      "        [0.0030, 0.9974],\n",
      "        [0.0026, 0.9975],\n",
      "        [0.9591, 0.0418]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0021, 0.9984],\n",
      "        [0.0185, 0.9831],\n",
      "        [0.9611, 0.0410],\n",
      "        [0.0015, 0.9987]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 8 [12/19 (63%)]\tTrain Loss: 0.104207\n",
      "tensor([[1.2409e-03, 9.9888e-01],\n",
      "        [6.4257e-01, 3.8294e-01],\n",
      "        [9.4403e-01, 4.9833e-02],\n",
      "        [1.8240e-04, 9.9988e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.8584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.9983e-01, 9.1695e-02],\n",
      "        [2.0645e-04, 9.9985e-01],\n",
      "        [8.2875e-01, 1.6778e-01],\n",
      "        [1.7398e-03, 9.9859e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0562, 0.9556],\n",
      "        [0.0685, 0.9399],\n",
      "        [0.0240, 0.9764],\n",
      "        [0.0137, 0.9872]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[5.9067e-01, 4.3330e-01],\n",
      "        [7.5290e-04, 9.9933e-01],\n",
      "        [5.3535e-02, 9.5558e-01],\n",
      "        [4.2916e-02, 9.6004e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 8 [16/19 (84%)]\tTrain Loss: 0.130743\n",
      "tensor([[5.0190e-01, 4.8839e-01],\n",
      "        [8.0285e-05, 9.9995e-01],\n",
      "        [8.8721e-01, 1.0771e-01],\n",
      "        [1.1680e-02, 9.8899e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.4242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0302, 0.9729]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1193, Accuracy: 63/73 (86%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(1) tensor(0) tensor(3)\n",
      "tensor(7) tensor(1) tensor(1) tensor(3)\n",
      "tensor(10) tensor(1) tensor(2) tensor(3)\n",
      "tensor(13) tensor(1) tensor(2) tensor(3)\n",
      "TP= tensor(13) TN= tensor(1) FN= tensor(2) FP= tensor(3)\n",
      "TP+FP tensor(16)\n",
      "precision 0.8125\n",
      "recall 0.8666666666666667\n",
      "F1 0.8387096774193549\n",
      "acc 0.7368421052631579\n",
      "AUC 0.8833333333333333\n",
      "\n",
      "Test set: Average loss: 0.1238, Accuracy: 14/19 (74%)\n",
      "\n",
      "tensor([[1.5497e-03, 9.9884e-01],\n",
      "        [1.2588e-04, 9.9989e-01],\n",
      "        [8.6280e-01, 1.3733e-01],\n",
      "        [8.7244e-01, 1.2928e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.3528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 9 [0/19 (0%)]\tTrain Loss: 0.088200\n",
      "tensor([[0.9676, 0.0311],\n",
      "        [0.0031, 0.9973],\n",
      "        [0.0141, 0.9879],\n",
      "        [0.0015, 0.9988]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0597, 0.9341],\n",
      "        [0.8576, 0.1386],\n",
      "        [0.0018, 0.9988],\n",
      "        [0.0066, 0.9947]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[9.9448e-04, 9.9922e-01],\n",
      "        [9.0605e-01, 9.5644e-02],\n",
      "        [7.4822e-01, 2.4451e-01],\n",
      "        [2.5074e-04, 9.9981e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.8191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0038, 0.9968],\n",
      "        [0.9729, 0.0281],\n",
      "        [0.0040, 0.9964],\n",
      "        [0.0019, 0.9983]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 9 [4/19 (21%)]\tTrain Loss: 0.079571\n",
      "tensor([[0.0126, 0.9896],\n",
      "        [0.0089, 0.9924],\n",
      "        [0.4181, 0.6137],\n",
      "        [0.0216, 0.9779]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[1.7820e-01, 8.1570e-01],\n",
      "        [8.9114e-04, 9.9919e-01],\n",
      "        [8.5251e-01, 1.4751e-01],\n",
      "        [4.3807e-03, 9.9686e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0033, 0.9974],\n",
      "        [0.0138, 0.9872],\n",
      "        [0.9328, 0.0699],\n",
      "        [0.0086, 0.9924]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0062, 0.9944],\n",
      "        [0.9665, 0.0370],\n",
      "        [0.0047, 0.9958],\n",
      "        [0.0041, 0.9965]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 9 [8/19 (42%)]\tTrain Loss: 0.080009\n",
      "tensor([[0.0156, 0.9840],\n",
      "        [0.1554, 0.8693],\n",
      "        [0.0356, 0.9669],\n",
      "        [0.0253, 0.9769]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.7149e-01, 1.2633e-01],\n",
      "        [9.0725e-01, 9.0018e-02],\n",
      "        [2.4758e-03, 9.9795e-01],\n",
      "        [2.9778e-05, 9.9998e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0020, 0.9982],\n",
      "        [0.9648, 0.0354],\n",
      "        [0.0057, 0.9953],\n",
      "        [0.0063, 0.9942]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0152, 0.9873],\n",
      "        [0.0047, 0.9958],\n",
      "        [0.0210, 0.9823],\n",
      "        [0.7159, 0.2840]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 9 [12/19 (63%)]\tTrain Loss: 0.121366\n",
      "tensor([[1.2007e-01, 8.8173e-01],\n",
      "        [9.6341e-01, 3.5137e-02],\n",
      "        [3.7456e-04, 9.9967e-01],\n",
      "        [2.6597e-03, 9.9803e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.5859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[3.7997e-02, 9.6288e-01],\n",
      "        [4.0070e-03, 9.9666e-01],\n",
      "        [5.3050e-04, 9.9959e-01],\n",
      "        [9.6553e-01, 3.3668e-02]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0013, 0.9989],\n",
      "        [0.0036, 0.9966],\n",
      "        [0.0184, 0.9837],\n",
      "        [0.9487, 0.0492]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7975, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0101, 0.9923],\n",
      "        [0.0686, 0.9358],\n",
      "        [0.0409, 0.9625],\n",
      "        [0.0417, 0.9594]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 9 [16/19 (84%)]\tTrain Loss: 0.083740\n",
      "tensor([[9.7850e-04, 9.9933e-01],\n",
      "        [1.5472e-02, 9.8474e-01],\n",
      "        [9.4115e-01, 5.7552e-02],\n",
      "        [1.4197e-02, 9.8562e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0364, 0.9678]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1176, Accuracy: 64/73 (88%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(3) tensor(0) tensor(1)\n",
      "tensor(7) tensor(3) tensor(1) tensor(1)\n",
      "tensor(11) tensor(3) tensor(1) tensor(1)\n",
      "tensor(14) tensor(3) tensor(1) tensor(1)\n",
      "TP= tensor(14) TN= tensor(3) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(15)\n",
      "precision 0.9333333333333333\n",
      "recall 0.9333333333333333\n",
      "F1 0.9333333333333333\n",
      "acc 0.8947368421052632\n",
      "AUC 0.9166666666666666\n",
      "\n",
      "Test set: Average loss: 0.1179, Accuracy: 17/19 (89%)\n",
      "\n",
      "tensor([[8.4207e-01, 1.5342e-01],\n",
      "        [3.9724e-03, 9.9582e-01],\n",
      "        [5.5436e-05, 9.9997e-01],\n",
      "        [9.0272e-01, 9.1159e-02]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 10 [0/19 (0%)]\tTrain Loss: 0.087703\n",
      "tensor([[0.0048, 0.9959],\n",
      "        [0.0755, 0.9380],\n",
      "        [0.0725, 0.9328],\n",
      "        [0.0589, 0.9397]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[2.6428e-03, 9.9770e-01],\n",
      "        [2.6255e-02, 9.7308e-01],\n",
      "        [9.7464e-01, 2.6582e-02],\n",
      "        [4.8952e-04, 9.9963e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.8066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[6.3671e-01, 3.7975e-01],\n",
      "        [6.4218e-01, 3.2281e-01],\n",
      "        [2.3415e-02, 9.7738e-01],\n",
      "        [6.4420e-05, 9.9996e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "criterion tensor(1.0721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0047, 0.9957],\n",
      "        [0.0437, 0.9516],\n",
      "        [0.0024, 0.9981],\n",
      "        [0.6729, 0.3625]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 10 [4/19 (21%)]\tTrain Loss: 0.124621\n",
      "tensor([[0.0457, 0.9615],\n",
      "        [0.0050, 0.9954],\n",
      "        [0.0230, 0.9815],\n",
      "        [0.1782, 0.8232]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[6.5637e-04, 9.9947e-01],\n",
      "        [9.1334e-01, 7.6508e-02],\n",
      "        [2.9135e-04, 9.9977e-01],\n",
      "        [7.7306e-01, 2.2107e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0340, 0.9710],\n",
      "        [0.0322, 0.9713],\n",
      "        [0.2277, 0.7677],\n",
      "        [0.0047, 0.9957]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.4939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0011, 0.9991],\n",
      "        [0.0059, 0.9946],\n",
      "        [0.0096, 0.9901],\n",
      "        [0.9647, 0.0378]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 10 [8/19 (42%)]\tTrain Loss: 0.081423\n",
      "tensor([[0.0046, 0.9960],\n",
      "        [0.0049, 0.9959],\n",
      "        [0.0053, 0.9956],\n",
      "        [0.9636, 0.0367]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0204, 0.9820],\n",
      "        [0.0036, 0.9966],\n",
      "        [0.8694, 0.1287],\n",
      "        [0.0020, 0.9985]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[7.9049e-04, 9.9926e-01],\n",
      "        [1.5586e-04, 9.9989e-01],\n",
      "        [7.4236e-01, 2.4944e-01],\n",
      "        [9.1687e-01, 8.1889e-02]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.3660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[1.4478e-02, 9.8653e-01],\n",
      "        [8.4897e-01, 1.4586e-01],\n",
      "        [7.9843e-01, 2.0011e-01],\n",
      "        [4.0394e-05, 9.9998e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 10 [12/19 (63%)]\tTrain Loss: 0.143873\n",
      "tensor([[0.0093, 0.9909],\n",
      "        [0.0090, 0.9922],\n",
      "        [0.7588, 0.2621],\n",
      "        [0.0118, 0.9891]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0150, 0.9858],\n",
      "        [0.0118, 0.9908],\n",
      "        [0.2735, 0.7467],\n",
      "        [0.0208, 0.9811]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0178, 0.9801],\n",
      "        [0.0874, 0.9116],\n",
      "        [0.0227, 0.9826],\n",
      "        [0.0287, 0.9755]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[3.1390e-06, 1.0000e+00],\n",
      "        [7.9476e-01, 1.9853e-01],\n",
      "        [7.5862e-01, 2.3163e-01],\n",
      "        [3.5972e-01, 6.2706e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.5129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 10 [16/19 (84%)]\tTrain Loss: 0.138668\n",
      "tensor([[0.0181, 0.9803],\n",
      "        [0.1122, 0.8975],\n",
      "        [0.0779, 0.9251],\n",
      "        [0.0086, 0.9935]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0273, 0.9750]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1193, Accuracy: 62/73 (85%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(4) tensor(0) tensor(0)\n",
      "tensor(7) tensor(4) tensor(1) tensor(0)\n",
      "tensor(10) tensor(4) tensor(2) tensor(0)\n",
      "tensor(13) tensor(4) tensor(2) tensor(0)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(2) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 0.8666666666666667\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.9166666666666666\n",
      "\n",
      "Test set: Average loss: 0.1157, Accuracy: 17/19 (89%)\n",
      "\n",
      "tensor([[2.1006e-02, 9.7806e-01],\n",
      "        [8.2474e-06, 1.0000e+00],\n",
      "        [8.9686e-01, 9.6381e-02],\n",
      "        [8.5454e-01, 1.3961e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.7699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 11 [0/19 (0%)]\tTrain Loss: 0.126441\n",
      "tensor([[0.0049, 0.9955],\n",
      "        [0.3161, 0.6978],\n",
      "        [0.0068, 0.9944],\n",
      "        [0.0600, 0.9468]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.2779, 0.7172],\n",
      "        [0.0104, 0.9911],\n",
      "        [0.2900, 0.7054],\n",
      "        [0.0031, 0.9974]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0013, 0.9989],\n",
      "        [0.0764, 0.9320],\n",
      "        [0.9214, 0.0714],\n",
      "        [0.0024, 0.9978]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9717, 0.0287],\n",
      "        [0.0028, 0.9978],\n",
      "        [0.0070, 0.9937],\n",
      "        [0.0017, 0.9984]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.8031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 11 [4/19 (21%)]\tTrain Loss: 0.086255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0083, 0.9932],\n",
      "        [0.9535, 0.0449],\n",
      "        [0.0068, 0.9929],\n",
      "        [0.0018, 0.9987]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[1.3587e-02, 9.8755e-01],\n",
      "        [1.9597e-02, 9.8122e-01],\n",
      "        [7.7998e-04, 9.9931e-01],\n",
      "        [8.9269e-01, 1.2479e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[9.1074e-01, 8.8767e-02],\n",
      "        [8.0793e-01, 1.7250e-01],\n",
      "        [9.8693e-04, 9.9922e-01],\n",
      "        [1.1359e-04, 9.9992e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.8092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0728, 0.9391],\n",
      "        [0.0872, 0.9167],\n",
      "        [0.0146, 0.9863],\n",
      "        [0.0074, 0.9933]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 11 [8/19 (42%)]\tTrain Loss: 0.084443\n",
      "tensor([[0.0017, 0.9987],\n",
      "        [0.1165, 0.8704],\n",
      "        [0.8456, 0.1537],\n",
      "        [0.0016, 0.9987]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.9631, 0.0370],\n",
      "        [0.0024, 0.9977],\n",
      "        [0.0065, 0.9951],\n",
      "        [0.0057, 0.9943]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0207, 0.9827],\n",
      "        [0.0370, 0.9632],\n",
      "        [0.0148, 0.9872],\n",
      "        [0.0513, 0.9541]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0177, 0.9845],\n",
      "        [0.0179, 0.9841],\n",
      "        [0.0823, 0.9267],\n",
      "        [0.0210, 0.9813]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 11 [12/19 (63%)]\tTrain Loss: 0.082900\n",
      "tensor([[6.6175e-01, 3.3657e-01],\n",
      "        [5.7408e-01, 4.1077e-01],\n",
      "        [4.6315e-05, 9.9996e-01],\n",
      "        [4.6963e-02, 9.6096e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.6807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0081, 0.9927],\n",
      "        [0.9315, 0.0651],\n",
      "        [0.0044, 0.9958],\n",
      "        [0.0033, 0.9976]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0027, 0.9980],\n",
      "        [0.0139, 0.9863],\n",
      "        [0.9683, 0.0309],\n",
      "        [0.0012, 0.9989]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[4.4737e-02, 9.5754e-01],\n",
      "        [3.4576e-02, 9.6958e-01],\n",
      "        [1.4208e-04, 9.9988e-01],\n",
      "        [9.1924e-01, 8.4868e-02]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.5694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 11 [16/19 (84%)]\tTrain Loss: 0.141427\n",
      "tensor([[5.3282e-04, 9.9955e-01],\n",
      "        [7.9088e-01, 2.0019e-01],\n",
      "        [6.4388e-04, 9.9953e-01],\n",
      "        [8.7845e-01, 1.1360e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.3625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0294, 0.9730]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1211, Accuracy: 63/73 (86%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(0) tensor(2)\n",
      "tensor(7) tensor(2) tensor(1) tensor(2)\n",
      "tensor(10) tensor(2) tensor(2) tensor(2)\n",
      "tensor(13) tensor(2) tensor(2) tensor(2)\n",
      "TP= tensor(13) TN= tensor(2) FN= tensor(2) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 0.8666666666666667\n",
      "F1 0.8666666666666667\n",
      "acc 0.7894736842105263\n",
      "AUC 0.8833333333333333\n",
      "\n",
      "Test set: Average loss: 0.1267, Accuracy: 15/19 (79%)\n",
      "\n",
      "tensor([[5.7290e-03, 9.9624e-01],\n",
      "        [7.7348e-03, 9.9248e-01],\n",
      "        [9.7218e-01, 2.7100e-02],\n",
      "        [5.8660e-04, 9.9940e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 12 [0/19 (0%)]\tTrain Loss: 0.079695\n",
      "tensor([[9.6087e-01, 3.6533e-02],\n",
      "        [5.3522e-04, 9.9966e-01],\n",
      "        [2.2442e-03, 9.9784e-01],\n",
      "        [6.5137e-02, 9.3100e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.5448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0147, 0.9855],\n",
      "        [0.8457, 0.1655],\n",
      "        [0.0011, 0.9991],\n",
      "        [0.0170, 0.9844]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0081, 0.9921],\n",
      "        [0.2526, 0.7078],\n",
      "        [0.0445, 0.9646],\n",
      "        [0.0169, 0.9865]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[9.4469e-01, 5.6857e-02],\n",
      "        [1.0502e-02, 9.8972e-01],\n",
      "        [1.0810e-02, 9.9159e-01],\n",
      "        [8.5548e-04, 9.9931e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 12 [4/19 (21%)]\tTrain Loss: 0.080983\n",
      "tensor([[6.8442e-01, 3.5682e-01],\n",
      "        [7.8898e-04, 9.9934e-01],\n",
      "        [1.6111e-02, 9.8327e-01],\n",
      "        [3.6669e-02, 9.6630e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.7623e-01, 1.1186e-01],\n",
      "        [4.0255e-01, 6.2108e-01],\n",
      "        [7.2005e-04, 9.9943e-01],\n",
      "        [2.1903e-04, 9.9984e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.8886e-01, 1.0945e-01],\n",
      "        [3.5324e-03, 9.9674e-01],\n",
      "        [1.6537e-05, 9.9999e-01],\n",
      "        [9.1543e-01, 8.6120e-02]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0020, 0.9983],\n",
      "        [0.9180, 0.0782],\n",
      "        [0.0028, 0.9974],\n",
      "        [0.0209, 0.9828]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.7783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 12 [8/19 (42%)]\tTrain Loss: 0.119811\n",
      "tensor([[0.8347, 0.1843],\n",
      "        [0.0020, 0.9985],\n",
      "        [0.0042, 0.9962],\n",
      "        [0.0100, 0.9887]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[1.2481e-02, 9.8944e-01],\n",
      "        [5.7551e-02, 9.4008e-01],\n",
      "        [8.8618e-01, 1.1580e-01],\n",
      "        [7.0609e-04, 9.9940e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0139, 0.9892],\n",
      "        [0.0624, 0.9457],\n",
      "        [0.0119, 0.9889],\n",
      "        [0.0772, 0.9221]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[3.2258e-03, 9.9700e-01],\n",
      "        [5.4979e-02, 9.4789e-01],\n",
      "        [4.3147e-04, 9.9963e-01],\n",
      "        [9.4503e-01, 5.9604e-02]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.7738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 12 [12/19 (63%)]\tTrain Loss: 0.115858\n",
      "tensor([[0.9765, 0.0244],\n",
      "        [0.0042, 0.9963],\n",
      "        [0.0025, 0.9982],\n",
      "        [0.0028, 0.9973]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "criterion tensor(0.8044, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0104, 0.9913],\n",
      "        [0.0651, 0.9422],\n",
      "        [0.0475, 0.9604],\n",
      "        [0.0161, 0.9838]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.3314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[8.3936e-01, 1.5327e-01],\n",
      "        [2.3925e-06, 1.0000e+00],\n",
      "        [4.1179e-01, 5.6771e-01],\n",
      "        [6.8642e-01, 3.1368e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "criterion tensor(0.5048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0115, 0.9898],\n",
      "        [0.0047, 0.9959],\n",
      "        [0.7302, 0.2738],\n",
      "        [0.0084, 0.9924]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "criterion tensor(0.4749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Train Epoch: 12 [16/19 (84%)]\tTrain Loss: 0.118721\n",
      "tensor([[2.7831e-04, 9.9977e-01],\n",
      "        [1.9545e-02, 9.8170e-01],\n",
      "        [9.5361e-01, 4.6934e-02],\n",
      "        [1.4548e-02, 9.8761e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "criterion tensor(0.3242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor([[0.0274, 0.9752]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "criterion tensor(0.3276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "Train set: Average loss: 0.1325, Accuracy: 57/73 (78%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(4) tensor(0) tensor(0)\n",
      "tensor(7) tensor(4) tensor(1) tensor(0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-00a9066261de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-0bc42cb340f7>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtargetlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PA\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/covid/covid_new/torchxrayvision/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;31m#print(img_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAXVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;31m# Check that images are 2D arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/covid/covid_new/torchxrayvision/datasets.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(sample, maxval)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Scales images to be roughly [-1024 1024].\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m#sample = sample / np.std(sample)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/imageio/core/util.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, out, context)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \"\"\" So that we return a native numpy array (or scalar) when a\n\u001b[1;32m    184\u001b[0m         \u001b[0mreducting\u001b[0m \u001b[0mufunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "        \n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "for epoch in range(1, 1000+1):\n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    test(epoch)\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), \"model_backup/DenseNet_{}.pt\".format(epoch))  \n",
    "\n",
    "\n",
    "# state = {'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "#                  'optimizer': optimizer.state_dict(), 'scheduler' : scheduler}\n",
    "# torch.save(state, \"model_backup/AlexNetAdamState\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/19 (0%)]\tTrain Loss: 0.150896\n",
      "Train Epoch: 1 [4/19 (21%)]\tTrain Loss: 0.185697\n",
      "Train Epoch: 1 [8/19 (42%)]\tTrain Loss: 0.076104\n",
      "Train Epoch: 1 [12/19 (63%)]\tTrain Loss: 0.236814\n",
      "Train Epoch: 1 [16/19 (84%)]\tTrain Loss: 0.088191\n",
      "\n",
      "Train set: Average loss: 0.1488, Accuracy: 55/73 (75%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(1) tensor(0) tensor(2)\n",
      "tensor(9) tensor(1) tensor(0) tensor(2)\n",
      "tensor(11) tensor(1) tensor(0) tensor(4)\n",
      "tensor(13) tensor(1) tensor(0) tensor(5)\n",
      "TP= tensor(13) TN= tensor(1) FN= tensor(0) FP= tensor(5)\n",
      "TP+FP tensor(18)\n",
      "precision 0.7222222222222222\n",
      "recall 1.0\n",
      "F1 0.8387096774193548\n",
      "acc 0.7368421052631579\n",
      "AUC 0.5\n",
      "\n",
      "Test set: Average loss: 0.1416, Accuracy: 14/19 (74%)\n",
      "\n",
      "Train Epoch: 2 [0/19 (0%)]\tTrain Loss: 0.063784\n",
      "Train Epoch: 2 [4/19 (21%)]\tTrain Loss: 0.083055\n",
      "Train Epoch: 2 [8/19 (42%)]\tTrain Loss: 0.082180\n",
      "Train Epoch: 2 [12/19 (63%)]\tTrain Loss: 0.060942\n",
      "Train Epoch: 2 [16/19 (84%)]\tTrain Loss: 0.076581\n",
      "\n",
      "Train set: Average loss: 0.1156, Accuracy: 59/73 (81%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(3) tensor(1) tensor(2)\n",
      "tensor(12) tensor(4) tensor(1) tensor(2)\n",
      "TP= tensor(12) TN= tensor(4) FN= tensor(1) FP= tensor(2)\n",
      "TP+FP tensor(14)\n",
      "precision 0.8571428571428571\n",
      "recall 0.9230769230769231\n",
      "F1 0.888888888888889\n",
      "acc 0.8421052631578947\n",
      "AUC 0.5256410256410257\n",
      "\n",
      "Test set: Average loss: 0.1263, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 3 [0/19 (0%)]\tTrain Loss: 0.109057\n",
      "Train Epoch: 3 [4/19 (21%)]\tTrain Loss: 0.071156\n",
      "Train Epoch: 3 [8/19 (42%)]\tTrain Loss: 0.277111\n",
      "Train Epoch: 3 [12/19 (63%)]\tTrain Loss: 0.071468\n",
      "Train Epoch: 3 [16/19 (84%)]\tTrain Loss: 0.079818\n",
      "\n",
      "Train set: Average loss: 0.1124, Accuracy: 60/73 (82%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(2) tensor(0) tensor(3)\n",
      "tensor(13) tensor(3) tensor(0) tensor(3)\n",
      "TP= tensor(13) TN= tensor(3) FN= tensor(0) FP= tensor(3)\n",
      "TP+FP tensor(16)\n",
      "precision 0.8125\n",
      "recall 1.0\n",
      "F1 0.896551724137931\n",
      "acc 0.8421052631578947\n",
      "AUC 0.7948717948717949\n",
      "\n",
      "Test set: Average loss: 0.1154, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 4 [0/19 (0%)]\tTrain Loss: 0.056062\n",
      "Train Epoch: 4 [4/19 (21%)]\tTrain Loss: 0.052782\n",
      "Train Epoch: 4 [8/19 (42%)]\tTrain Loss: 0.073920\n",
      "Train Epoch: 4 [12/19 (63%)]\tTrain Loss: 0.056694\n",
      "Train Epoch: 4 [16/19 (84%)]\tTrain Loss: 0.061717\n",
      "\n",
      "Train set: Average loss: 0.1082, Accuracy: 60/73 (82%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5128205128205128\n",
      "\n",
      "Test set: Average loss: 0.0830, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/19 (0%)]\tTrain Loss: 0.084209\n",
      "Train Epoch: 5 [4/19 (21%)]\tTrain Loss: 0.076489\n",
      "Train Epoch: 5 [8/19 (42%)]\tTrain Loss: 0.078621\n",
      "Train Epoch: 5 [12/19 (63%)]\tTrain Loss: 0.025055\n",
      "Train Epoch: 5 [16/19 (84%)]\tTrain Loss: 0.058456\n",
      "\n",
      "Train set: Average loss: 0.0955, Accuracy: 63/73 (86%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.6794871794871795\n",
      "\n",
      "Test set: Average loss: 0.0894, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 6 [0/19 (0%)]\tTrain Loss: 0.071687\n",
      "Train Epoch: 6 [4/19 (21%)]\tTrain Loss: 0.040449\n",
      "Train Epoch: 6 [8/19 (42%)]\tTrain Loss: 0.182945\n",
      "Train Epoch: 6 [12/19 (63%)]\tTrain Loss: 0.203027\n",
      "Train Epoch: 6 [16/19 (84%)]\tTrain Loss: 0.134152\n",
      "\n",
      "Train set: Average loss: 0.1046, Accuracy: 60/73 (82%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(0) tensor(1) tensor(3)\n",
      "tensor(8) tensor(0) tensor(1) tensor(3)\n",
      "tensor(10) tensor(1) tensor(1) tensor(4)\n",
      "tensor(12) tensor(2) tensor(1) tensor(4)\n",
      "TP= tensor(12) TN= tensor(2) FN= tensor(1) FP= tensor(4)\n",
      "TP+FP tensor(16)\n",
      "precision 0.75\n",
      "recall 0.9230769230769231\n",
      "F1 0.8275862068965517\n",
      "acc 0.7368421052631579\n",
      "AUC 0.9871794871794872\n",
      "\n",
      "Test set: Average loss: 0.0955, Accuracy: 14/19 (74%)\n",
      "\n",
      "Train Epoch: 7 [0/19 (0%)]\tTrain Loss: 0.064011\n",
      "Train Epoch: 7 [4/19 (21%)]\tTrain Loss: 0.160320\n",
      "Train Epoch: 7 [8/19 (42%)]\tTrain Loss: 0.075833\n",
      "Train Epoch: 7 [12/19 (63%)]\tTrain Loss: 0.156507\n",
      "Train Epoch: 7 [16/19 (84%)]\tTrain Loss: 0.072201\n",
      "\n",
      "Train set: Average loss: 0.0815, Accuracy: 66/73 (90%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.4487179487179488\n",
      "\n",
      "Test set: Average loss: 0.0695, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 8 [0/19 (0%)]\tTrain Loss: 0.097298\n",
      "Train Epoch: 8 [4/19 (21%)]\tTrain Loss: 0.239894\n",
      "Train Epoch: 8 [8/19 (42%)]\tTrain Loss: 0.085409\n",
      "Train Epoch: 8 [12/19 (63%)]\tTrain Loss: 0.089698\n",
      "Train Epoch: 8 [16/19 (84%)]\tTrain Loss: 0.033120\n",
      "\n",
      "Train set: Average loss: 0.0803, Accuracy: 62/73 (85%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(3) tensor(0) tensor(3)\n",
      "TP= tensor(13) TN= tensor(3) FN= tensor(0) FP= tensor(3)\n",
      "TP+FP tensor(16)\n",
      "precision 0.8125\n",
      "recall 1.0\n",
      "F1 0.896551724137931\n",
      "acc 0.8421052631578947\n",
      "AUC 0.7692307692307693\n",
      "\n",
      "Test set: Average loss: 0.0933, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 9 [0/19 (0%)]\tTrain Loss: 0.031916\n",
      "Train Epoch: 9 [4/19 (21%)]\tTrain Loss: 0.039381\n",
      "Train Epoch: 9 [8/19 (42%)]\tTrain Loss: 0.055596\n",
      "Train Epoch: 9 [12/19 (63%)]\tTrain Loss: 0.073133\n",
      "Train Epoch: 9 [16/19 (84%)]\tTrain Loss: 0.040450\n",
      "\n",
      "Train set: Average loss: 0.0838, Accuracy: 66/73 (90%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(1) tensor(0) tensor(2)\n",
      "tensor(9) tensor(1) tensor(0) tensor(2)\n",
      "tensor(11) tensor(1) tensor(0) tensor(4)\n",
      "tensor(13) tensor(1) tensor(0) tensor(5)\n",
      "TP= tensor(13) TN= tensor(1) FN= tensor(0) FP= tensor(5)\n",
      "TP+FP tensor(18)\n",
      "precision 0.7222222222222222\n",
      "recall 1.0\n",
      "F1 0.8387096774193548\n",
      "acc 0.7368421052631579\n",
      "AUC 0.6025641025641025\n",
      "\n",
      "Test set: Average loss: 0.1035, Accuracy: 14/19 (74%)\n",
      "\n",
      "Train Epoch: 10 [0/19 (0%)]\tTrain Loss: 0.048281\n",
      "Train Epoch: 10 [4/19 (21%)]\tTrain Loss: 0.026753\n",
      "Train Epoch: 10 [8/19 (42%)]\tTrain Loss: 0.039492\n",
      "Train Epoch: 10 [12/19 (63%)]\tTrain Loss: 0.014812\n",
      "Train Epoch: 10 [16/19 (84%)]\tTrain Loss: 0.191544\n",
      "\n",
      "Train set: Average loss: 0.0808, Accuracy: 63/73 (86%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(1) tensor(0) tensor(2)\n",
      "tensor(9) tensor(1) tensor(0) tensor(2)\n",
      "tensor(11) tensor(1) tensor(0) tensor(4)\n",
      "tensor(13) tensor(1) tensor(0) tensor(5)\n",
      "TP= tensor(13) TN= tensor(1) FN= tensor(0) FP= tensor(5)\n",
      "TP+FP tensor(18)\n",
      "precision 0.7222222222222222\n",
      "recall 1.0\n",
      "F1 0.8387096774193548\n",
      "acc 0.7368421052631579\n",
      "AUC 0.7307692307692308\n",
      "\n",
      "Test set: Average loss: 0.1547, Accuracy: 14/19 (74%)\n",
      "\n",
      "Train Epoch: 11 [0/19 (0%)]\tTrain Loss: 0.029062\n",
      "Train Epoch: 11 [4/19 (21%)]\tTrain Loss: 0.028361\n",
      "Train Epoch: 11 [8/19 (42%)]\tTrain Loss: 0.160176\n",
      "Train Epoch: 11 [12/19 (63%)]\tTrain Loss: 0.030168\n",
      "Train Epoch: 11 [16/19 (84%)]\tTrain Loss: 0.144410\n",
      "\n",
      "Train set: Average loss: 0.0720, Accuracy: 62/73 (85%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.6666666666666667\n",
      "\n",
      "Test set: Average loss: 0.0779, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 12 [0/19 (0%)]\tTrain Loss: 0.029640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [4/19 (21%)]\tTrain Loss: 0.058886\n",
      "Train Epoch: 12 [8/19 (42%)]\tTrain Loss: 0.066597\n",
      "Train Epoch: 12 [12/19 (63%)]\tTrain Loss: 0.083127\n",
      "Train Epoch: 12 [16/19 (84%)]\tTrain Loss: 0.054436\n",
      "\n",
      "Train set: Average loss: 0.0845, Accuracy: 65/73 (89%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5\n",
      "\n",
      "Test set: Average loss: 0.0652, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 13 [0/19 (0%)]\tTrain Loss: 0.013141\n",
      "Train Epoch: 13 [4/19 (21%)]\tTrain Loss: 0.040769\n",
      "Train Epoch: 13 [8/19 (42%)]\tTrain Loss: 0.020952\n",
      "Train Epoch: 13 [12/19 (63%)]\tTrain Loss: 0.061563\n",
      "Train Epoch: 13 [16/19 (84%)]\tTrain Loss: 0.031045\n",
      "\n",
      "Train set: Average loss: 0.0647, Accuracy: 65/73 (89%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(4) tensor(1) tensor(2)\n",
      "TP= tensor(12) TN= tensor(4) FN= tensor(1) FP= tensor(2)\n",
      "TP+FP tensor(14)\n",
      "precision 0.8571428571428571\n",
      "recall 0.9230769230769231\n",
      "F1 0.888888888888889\n",
      "acc 0.8421052631578947\n",
      "AUC 0.6153846153846154\n",
      "\n",
      "Test set: Average loss: 0.1048, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 14 [0/19 (0%)]\tTrain Loss: 0.088705\n",
      "Train Epoch: 14 [4/19 (21%)]\tTrain Loss: 0.022208\n",
      "Train Epoch: 14 [8/19 (42%)]\tTrain Loss: 0.044016\n",
      "Train Epoch: 14 [12/19 (63%)]\tTrain Loss: 0.067124\n",
      "Train Epoch: 14 [16/19 (84%)]\tTrain Loss: 0.018324\n",
      "\n",
      "Train set: Average loss: 0.0513, Accuracy: 69/73 (95%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.4358974358974359\n",
      "\n",
      "Test set: Average loss: 0.0587, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 15 [0/19 (0%)]\tTrain Loss: 0.032498\n",
      "Train Epoch: 15 [4/19 (21%)]\tTrain Loss: 0.617791\n",
      "Train Epoch: 15 [8/19 (42%)]\tTrain Loss: 0.030297\n",
      "Train Epoch: 15 [12/19 (63%)]\tTrain Loss: 0.052435\n",
      "Train Epoch: 15 [16/19 (84%)]\tTrain Loss: 0.102497\n",
      "\n",
      "Train set: Average loss: 0.1010, Accuracy: 64/73 (88%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.8076923076923077\n",
      "\n",
      "Test set: Average loss: 0.0408, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 16 [0/19 (0%)]\tTrain Loss: 0.035125\n",
      "Train Epoch: 16 [4/19 (21%)]\tTrain Loss: 0.021417\n",
      "Train Epoch: 16 [8/19 (42%)]\tTrain Loss: 0.035302\n",
      "Train Epoch: 16 [12/19 (63%)]\tTrain Loss: 0.016918\n",
      "Train Epoch: 16 [16/19 (84%)]\tTrain Loss: 0.125058\n",
      "\n",
      "Train set: Average loss: 0.0733, Accuracy: 66/73 (90%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(11) tensor(5) tensor(2) tensor(1)\n",
      "TP= tensor(11) TN= tensor(5) FN= tensor(2) FP= tensor(1)\n",
      "TP+FP tensor(12)\n",
      "precision 0.9166666666666666\n",
      "recall 0.8461538461538461\n",
      "F1 0.8799999999999999\n",
      "acc 0.8421052631578947\n",
      "AUC 0.653846153846154\n",
      "\n",
      "Test set: Average loss: 0.0806, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 17 [0/19 (0%)]\tTrain Loss: 0.040960\n",
      "Train Epoch: 17 [4/19 (21%)]\tTrain Loss: 0.011036\n",
      "Train Epoch: 17 [8/19 (42%)]\tTrain Loss: 0.009670\n",
      "Train Epoch: 17 [12/19 (63%)]\tTrain Loss: 0.034356\n",
      "Train Epoch: 17 [16/19 (84%)]\tTrain Loss: 0.010905\n",
      "\n",
      "Train set: Average loss: 0.0656, Accuracy: 66/73 (90%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.782051282051282\n",
      "\n",
      "Test set: Average loss: 0.0783, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 18 [0/19 (0%)]\tTrain Loss: 0.064488\n",
      "Train Epoch: 18 [4/19 (21%)]\tTrain Loss: 0.043203\n",
      "Train Epoch: 18 [8/19 (42%)]\tTrain Loss: 0.045502\n",
      "Train Epoch: 18 [12/19 (63%)]\tTrain Loss: 0.014879\n",
      "Train Epoch: 18 [16/19 (84%)]\tTrain Loss: 0.132185\n",
      "\n",
      "Train set: Average loss: 0.0618, Accuracy: 67/73 (92%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.858974358974359\n",
      "\n",
      "Test set: Average loss: 0.0572, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 19 [0/19 (0%)]\tTrain Loss: 0.052251\n",
      "Train Epoch: 19 [4/19 (21%)]\tTrain Loss: 0.014570\n",
      "Train Epoch: 19 [8/19 (42%)]\tTrain Loss: 0.051237\n",
      "Train Epoch: 19 [12/19 (63%)]\tTrain Loss: 0.080846\n",
      "Train Epoch: 19 [16/19 (84%)]\tTrain Loss: 0.005937\n",
      "\n",
      "Train set: Average loss: 0.0354, Accuracy: 70/73 (96%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(3) tensor(1) tensor(2)\n",
      "tensor(12) tensor(4) tensor(1) tensor(2)\n",
      "TP= tensor(12) TN= tensor(4) FN= tensor(1) FP= tensor(2)\n",
      "TP+FP tensor(14)\n",
      "precision 0.8571428571428571\n",
      "recall 0.9230769230769231\n",
      "F1 0.888888888888889\n",
      "acc 0.8421052631578947\n",
      "AUC 0.46153846153846156\n",
      "\n",
      "Test set: Average loss: 0.0583, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 20 [0/19 (0%)]\tTrain Loss: 0.023101\n",
      "Train Epoch: 20 [4/19 (21%)]\tTrain Loss: 0.033102\n",
      "Train Epoch: 20 [8/19 (42%)]\tTrain Loss: 0.003689\n",
      "Train Epoch: 20 [12/19 (63%)]\tTrain Loss: 0.027357\n",
      "Train Epoch: 20 [16/19 (84%)]\tTrain Loss: 0.021385\n",
      "\n",
      "Train set: Average loss: 0.0436, Accuracy: 70/73 (96%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5\n",
      "\n",
      "Test set: Average loss: 0.0487, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 21 [0/19 (0%)]\tTrain Loss: 0.036144\n",
      "Train Epoch: 21 [4/19 (21%)]\tTrain Loss: 0.046321\n",
      "Train Epoch: 21 [8/19 (42%)]\tTrain Loss: 0.030231\n",
      "Train Epoch: 21 [12/19 (63%)]\tTrain Loss: 0.008505\n",
      "Train Epoch: 21 [16/19 (84%)]\tTrain Loss: 0.015542\n",
      "\n",
      "Train set: Average loss: 0.0615, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.48717948717948717\n",
      "\n",
      "Test set: Average loss: 0.0390, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 22 [0/19 (0%)]\tTrain Loss: 0.026280\n",
      "Train Epoch: 22 [4/19 (21%)]\tTrain Loss: 0.020029\n",
      "Train Epoch: 22 [8/19 (42%)]\tTrain Loss: 0.037239\n",
      "Train Epoch: 22 [12/19 (63%)]\tTrain Loss: 0.006437\n",
      "Train Epoch: 22 [16/19 (84%)]\tTrain Loss: 0.032477\n",
      "\n",
      "Train set: Average loss: 0.0250, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.39743589743589747\n",
      "\n",
      "Test set: Average loss: 0.0350, Accuracy: 18/19 (95%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [0/19 (0%)]\tTrain Loss: 0.012194\n",
      "Train Epoch: 23 [4/19 (21%)]\tTrain Loss: 0.029856\n",
      "Train Epoch: 23 [8/19 (42%)]\tTrain Loss: 0.045509\n",
      "Train Epoch: 23 [12/19 (63%)]\tTrain Loss: 0.031632\n",
      "Train Epoch: 23 [16/19 (84%)]\tTrain Loss: 0.027967\n",
      "\n",
      "Train set: Average loss: 0.0214, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.46153846153846156\n",
      "\n",
      "Test set: Average loss: 0.0386, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 24 [0/19 (0%)]\tTrain Loss: 0.041722\n",
      "Train Epoch: 24 [4/19 (21%)]\tTrain Loss: 0.002985\n",
      "Train Epoch: 24 [8/19 (42%)]\tTrain Loss: 0.009260\n",
      "Train Epoch: 24 [12/19 (63%)]\tTrain Loss: 0.049795\n",
      "Train Epoch: 24 [16/19 (84%)]\tTrain Loss: 0.049645\n",
      "\n",
      "Train set: Average loss: 0.0693, Accuracy: 70/73 (96%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.7051282051282052\n",
      "\n",
      "Test set: Average loss: 0.0687, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 25 [0/19 (0%)]\tTrain Loss: 0.032325\n",
      "Train Epoch: 25 [4/19 (21%)]\tTrain Loss: 0.004807\n",
      "Train Epoch: 25 [8/19 (42%)]\tTrain Loss: 0.046377\n",
      "Train Epoch: 25 [12/19 (63%)]\tTrain Loss: 0.087955\n",
      "Train Epoch: 25 [16/19 (84%)]\tTrain Loss: 0.043673\n",
      "\n",
      "Train set: Average loss: 0.0650, Accuracy: 70/73 (96%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.38461538461538464\n",
      "\n",
      "Test set: Average loss: 0.0524, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 26 [0/19 (0%)]\tTrain Loss: 0.008772\n",
      "Train Epoch: 26 [4/19 (21%)]\tTrain Loss: 0.009964\n",
      "Train Epoch: 26 [8/19 (42%)]\tTrain Loss: 0.004740\n",
      "Train Epoch: 26 [12/19 (63%)]\tTrain Loss: 0.027936\n",
      "Train Epoch: 26 [16/19 (84%)]\tTrain Loss: 0.006207\n",
      "\n",
      "Train set: Average loss: 0.0262, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.39743589743589747\n",
      "\n",
      "Test set: Average loss: 0.0564, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 27 [0/19 (0%)]\tTrain Loss: 0.081918\n",
      "Train Epoch: 27 [4/19 (21%)]\tTrain Loss: 0.008668\n",
      "Train Epoch: 27 [8/19 (42%)]\tTrain Loss: 0.003088\n",
      "Train Epoch: 27 [12/19 (63%)]\tTrain Loss: 0.047888\n",
      "Train Epoch: 27 [16/19 (84%)]\tTrain Loss: 0.003802\n",
      "\n",
      "Train set: Average loss: 0.0358, Accuracy: 69/73 (95%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.6025641025641026\n",
      "\n",
      "Test set: Average loss: 0.0551, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 28 [0/19 (0%)]\tTrain Loss: 0.043107\n",
      "Train Epoch: 28 [4/19 (21%)]\tTrain Loss: 0.013587\n",
      "Train Epoch: 28 [8/19 (42%)]\tTrain Loss: 0.238603\n",
      "Train Epoch: 28 [12/19 (63%)]\tTrain Loss: 0.046234\n",
      "Train Epoch: 28 [16/19 (84%)]\tTrain Loss: 0.007382\n",
      "\n",
      "Train set: Average loss: 0.0784, Accuracy: 69/73 (95%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(1) tensor(0) tensor(2)\n",
      "tensor(9) tensor(1) tensor(0) tensor(2)\n",
      "tensor(11) tensor(2) tensor(0) tensor(3)\n",
      "tensor(13) tensor(3) tensor(0) tensor(3)\n",
      "TP= tensor(13) TN= tensor(3) FN= tensor(0) FP= tensor(3)\n",
      "TP+FP tensor(16)\n",
      "precision 0.8125\n",
      "recall 1.0\n",
      "F1 0.896551724137931\n",
      "acc 0.8421052631578947\n",
      "AUC 0.6794871794871795\n",
      "\n",
      "Test set: Average loss: 0.0897, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 29 [0/19 (0%)]\tTrain Loss: 0.032874\n",
      "Train Epoch: 29 [4/19 (21%)]\tTrain Loss: 0.236948\n",
      "Train Epoch: 29 [8/19 (42%)]\tTrain Loss: 0.099926\n",
      "Train Epoch: 29 [12/19 (63%)]\tTrain Loss: 0.005213\n",
      "Train Epoch: 29 [16/19 (84%)]\tTrain Loss: 0.028719\n",
      "\n",
      "Train set: Average loss: 0.0538, Accuracy: 66/73 (90%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(11) tensor(6) tensor(2) tensor(0)\n",
      "TP= tensor(11) TN= tensor(6) FN= tensor(2) FP= tensor(0)\n",
      "TP+FP tensor(11)\n",
      "precision 1.0\n",
      "recall 0.8461538461538461\n",
      "F1 0.9166666666666666\n",
      "acc 0.8947368421052632\n",
      "AUC 0.32051282051282054\n",
      "\n",
      "Test set: Average loss: 0.0771, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 30 [0/19 (0%)]\tTrain Loss: 0.031816\n",
      "Train Epoch: 30 [4/19 (21%)]\tTrain Loss: 0.009234\n",
      "Train Epoch: 30 [8/19 (42%)]\tTrain Loss: 0.098963\n",
      "Train Epoch: 30 [12/19 (63%)]\tTrain Loss: 0.005341\n",
      "Train Epoch: 30 [16/19 (84%)]\tTrain Loss: 0.016389\n",
      "\n",
      "Train set: Average loss: 0.0364, Accuracy: 70/73 (96%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.6025641025641025\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 31 [0/19 (0%)]\tTrain Loss: 0.013117\n",
      "Train Epoch: 31 [4/19 (21%)]\tTrain Loss: 0.014643\n",
      "Train Epoch: 31 [8/19 (42%)]\tTrain Loss: 0.004374\n",
      "Train Epoch: 31 [12/19 (63%)]\tTrain Loss: 0.018596\n",
      "Train Epoch: 31 [16/19 (84%)]\tTrain Loss: 0.057394\n",
      "\n",
      "Train set: Average loss: 0.0380, Accuracy: 69/73 (95%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.5256410256410257\n",
      "\n",
      "Test set: Average loss: 0.0372, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 32 [0/19 (0%)]\tTrain Loss: 0.022490\n",
      "Train Epoch: 32 [4/19 (21%)]\tTrain Loss: 0.136685\n",
      "Train Epoch: 32 [8/19 (42%)]\tTrain Loss: 0.004235\n",
      "Train Epoch: 32 [12/19 (63%)]\tTrain Loss: 0.013752\n",
      "Train Epoch: 32 [16/19 (84%)]\tTrain Loss: 0.020317\n",
      "\n",
      "Train set: Average loss: 0.0670, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5\n",
      "\n",
      "Test set: Average loss: 0.0515, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 33 [0/19 (0%)]\tTrain Loss: 0.070064\n",
      "Train Epoch: 33 [4/19 (21%)]\tTrain Loss: 0.046498\n",
      "Train Epoch: 33 [8/19 (42%)]\tTrain Loss: 0.038142\n",
      "Train Epoch: 33 [12/19 (63%)]\tTrain Loss: 0.004714\n",
      "Train Epoch: 33 [16/19 (84%)]\tTrain Loss: 0.077681\n",
      "\n",
      "Train set: Average loss: 0.0405, Accuracy: 67/73 (92%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.4487179487179488\n",
      "\n",
      "Test set: Average loss: 0.0378, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 34 [0/19 (0%)]\tTrain Loss: 0.007400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 [4/19 (21%)]\tTrain Loss: 0.003278\n",
      "Train Epoch: 34 [8/19 (42%)]\tTrain Loss: 0.017126\n",
      "Train Epoch: 34 [12/19 (63%)]\tTrain Loss: 0.002733\n",
      "Train Epoch: 34 [16/19 (84%)]\tTrain Loss: 0.026939\n",
      "\n",
      "Train set: Average loss: 0.0166, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.6538461538461539\n",
      "\n",
      "Test set: Average loss: 0.0395, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 35 [0/19 (0%)]\tTrain Loss: 0.018746\n",
      "Train Epoch: 35 [4/19 (21%)]\tTrain Loss: 0.001863\n",
      "Train Epoch: 35 [8/19 (42%)]\tTrain Loss: 0.024366\n",
      "Train Epoch: 35 [12/19 (63%)]\tTrain Loss: 0.024036\n",
      "Train Epoch: 35 [16/19 (84%)]\tTrain Loss: 0.004547\n",
      "\n",
      "Train set: Average loss: 0.0130, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.576923076923077\n",
      "\n",
      "Test set: Average loss: 0.0359, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 36 [0/19 (0%)]\tTrain Loss: 0.002146\n",
      "Train Epoch: 36 [4/19 (21%)]\tTrain Loss: 0.013979\n",
      "Train Epoch: 36 [8/19 (42%)]\tTrain Loss: 0.068561\n",
      "Train Epoch: 36 [12/19 (63%)]\tTrain Loss: 0.013815\n",
      "Train Epoch: 36 [16/19 (84%)]\tTrain Loss: 0.009536\n",
      "\n",
      "Train set: Average loss: 0.0168, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.43589743589743596\n",
      "\n",
      "Test set: Average loss: 0.0567, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 37 [0/19 (0%)]\tTrain Loss: 0.007413\n",
      "Train Epoch: 37 [4/19 (21%)]\tTrain Loss: 0.003903\n",
      "Train Epoch: 37 [8/19 (42%)]\tTrain Loss: 0.002143\n",
      "Train Epoch: 37 [12/19 (63%)]\tTrain Loss: 0.004438\n",
      "Train Epoch: 37 [16/19 (84%)]\tTrain Loss: 0.018761\n",
      "\n",
      "Train set: Average loss: 0.0618, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.4487179487179487\n",
      "\n",
      "Test set: Average loss: 0.0474, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 38 [0/19 (0%)]\tTrain Loss: 0.003675\n",
      "Train Epoch: 38 [4/19 (21%)]\tTrain Loss: 0.006393\n",
      "Train Epoch: 38 [8/19 (42%)]\tTrain Loss: 0.003298\n",
      "Train Epoch: 38 [12/19 (63%)]\tTrain Loss: 0.002687\n",
      "Train Epoch: 38 [16/19 (84%)]\tTrain Loss: 0.006521\n",
      "\n",
      "Train set: Average loss: 0.0501, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.358974358974359\n",
      "\n",
      "Test set: Average loss: 0.0555, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 39 [0/19 (0%)]\tTrain Loss: 0.016198\n",
      "Train Epoch: 39 [4/19 (21%)]\tTrain Loss: 0.027133\n",
      "Train Epoch: 39 [8/19 (42%)]\tTrain Loss: 0.003096\n",
      "Train Epoch: 39 [12/19 (63%)]\tTrain Loss: 0.006117\n",
      "Train Epoch: 39 [16/19 (84%)]\tTrain Loss: 0.007676\n",
      "\n",
      "Train set: Average loss: 0.0158, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.782051282051282\n",
      "\n",
      "Test set: Average loss: 0.0374, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 40 [0/19 (0%)]\tTrain Loss: 0.128487\n",
      "Train Epoch: 40 [4/19 (21%)]\tTrain Loss: 0.002066\n",
      "Train Epoch: 40 [8/19 (42%)]\tTrain Loss: 0.029262\n",
      "Train Epoch: 40 [12/19 (63%)]\tTrain Loss: 0.031923\n",
      "Train Epoch: 40 [16/19 (84%)]\tTrain Loss: 0.023201\n",
      "\n",
      "Train set: Average loss: 0.0248, Accuracy: 70/73 (96%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.6538461538461537\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 41 [0/19 (0%)]\tTrain Loss: 0.014393\n",
      "Train Epoch: 41 [4/19 (21%)]\tTrain Loss: 0.013432\n",
      "Train Epoch: 41 [8/19 (42%)]\tTrain Loss: 0.003724\n",
      "Train Epoch: 41 [12/19 (63%)]\tTrain Loss: 0.047318\n",
      "Train Epoch: 41 [16/19 (84%)]\tTrain Loss: 0.005059\n",
      "\n",
      "Train set: Average loss: 0.0258, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(2) tensor(0) tensor(1) tensor(1)\n",
      "tensor(4) tensor(1) tensor(1) tensor(2)\n",
      "tensor(8) tensor(1) tensor(1) tensor(2)\n",
      "tensor(10) tensor(2) tensor(1) tensor(3)\n",
      "tensor(12) tensor(3) tensor(1) tensor(3)\n",
      "TP= tensor(12) TN= tensor(3) FN= tensor(1) FP= tensor(3)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8\n",
      "recall 0.9230769230769231\n",
      "F1 0.8571428571428571\n",
      "acc 0.7894736842105263\n",
      "AUC 0.6025641025641025\n",
      "\n",
      "Test set: Average loss: 0.0983, Accuracy: 15/19 (79%)\n",
      "\n",
      "Train Epoch: 42 [0/19 (0%)]\tTrain Loss: 0.006133\n",
      "Train Epoch: 42 [4/19 (21%)]\tTrain Loss: 0.043302\n",
      "Train Epoch: 42 [8/19 (42%)]\tTrain Loss: 0.036167\n",
      "Train Epoch: 42 [12/19 (63%)]\tTrain Loss: 0.025740\n",
      "Train Epoch: 42 [16/19 (84%)]\tTrain Loss: 0.017368\n",
      "\n",
      "Train set: Average loss: 0.0611, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.46153846153846156\n",
      "\n",
      "Test set: Average loss: 0.0752, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 43 [0/19 (0%)]\tTrain Loss: 0.024101\n",
      "Train Epoch: 43 [4/19 (21%)]\tTrain Loss: 0.010816\n",
      "Train Epoch: 43 [8/19 (42%)]\tTrain Loss: 0.015992\n",
      "Train Epoch: 43 [12/19 (63%)]\tTrain Loss: 0.003675\n",
      "Train Epoch: 43 [16/19 (84%)]\tTrain Loss: 0.065924\n",
      "\n",
      "Train set: Average loss: 0.0287, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.42307692307692313\n",
      "\n",
      "Test set: Average loss: 0.0482, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 44 [0/19 (0%)]\tTrain Loss: 0.015753\n",
      "Train Epoch: 44 [4/19 (21%)]\tTrain Loss: 0.105735\n",
      "Train Epoch: 44 [8/19 (42%)]\tTrain Loss: 0.005950\n",
      "Train Epoch: 44 [12/19 (63%)]\tTrain Loss: 0.032548\n",
      "Train Epoch: 44 [16/19 (84%)]\tTrain Loss: 0.005039\n",
      "\n",
      "Train set: Average loss: 0.0653, Accuracy: 67/73 (92%)\n",
      "\n",
      "tensor(2) tensor(1) tensor(1) tensor(0)\n",
      "tensor(3) tensor(3) tensor(2) tensor(0)\n",
      "tensor(7) tensor(3) tensor(2) tensor(0)\n",
      "tensor(9) tensor(5) tensor(2) tensor(0)\n",
      "tensor(11) tensor(6) tensor(2) tensor(0)\n",
      "TP= tensor(11) TN= tensor(6) FN= tensor(2) FP= tensor(0)\n",
      "TP+FP tensor(11)\n",
      "precision 1.0\n",
      "recall 0.8461538461538461\n",
      "F1 0.9166666666666666\n",
      "acc 0.8947368421052632\n",
      "AUC 0.46153846153846156\n",
      "\n",
      "Test set: Average loss: 0.0536, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 45 [0/19 (0%)]\tTrain Loss: 0.010480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [4/19 (21%)]\tTrain Loss: 0.013753\n",
      "Train Epoch: 45 [8/19 (42%)]\tTrain Loss: 0.001156\n",
      "Train Epoch: 45 [12/19 (63%)]\tTrain Loss: 0.103938\n",
      "Train Epoch: 45 [16/19 (84%)]\tTrain Loss: 0.016001\n",
      "\n",
      "Train set: Average loss: 0.0176, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.5\n",
      "\n",
      "Test set: Average loss: 0.0548, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 46 [0/19 (0%)]\tTrain Loss: 0.029481\n",
      "Train Epoch: 46 [4/19 (21%)]\tTrain Loss: 0.005276\n",
      "Train Epoch: 46 [8/19 (42%)]\tTrain Loss: 0.002038\n",
      "Train Epoch: 46 [12/19 (63%)]\tTrain Loss: 0.022168\n",
      "Train Epoch: 46 [16/19 (84%)]\tTrain Loss: 0.002815\n",
      "\n",
      "Train set: Average loss: 0.0132, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.41025641025641035\n",
      "\n",
      "Test set: Average loss: 0.0469, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 47 [0/19 (0%)]\tTrain Loss: 0.027234\n",
      "Train Epoch: 47 [4/19 (21%)]\tTrain Loss: 0.008542\n",
      "Train Epoch: 47 [8/19 (42%)]\tTrain Loss: 0.001726\n",
      "Train Epoch: 47 [12/19 (63%)]\tTrain Loss: 0.001608\n",
      "Train Epoch: 47 [16/19 (84%)]\tTrain Loss: 0.013156\n",
      "\n",
      "Train set: Average loss: 0.0144, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.38461538461538464\n",
      "\n",
      "Test set: Average loss: 0.0458, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 48 [0/19 (0%)]\tTrain Loss: 0.003758\n",
      "Train Epoch: 48 [4/19 (21%)]\tTrain Loss: 0.002943\n",
      "Train Epoch: 48 [8/19 (42%)]\tTrain Loss: 0.001933\n",
      "Train Epoch: 48 [12/19 (63%)]\tTrain Loss: 0.000991\n",
      "Train Epoch: 48 [16/19 (84%)]\tTrain Loss: 0.006599\n",
      "\n",
      "Train set: Average loss: 0.0106, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5512820512820513\n",
      "\n",
      "Test set: Average loss: 0.0483, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 49 [0/19 (0%)]\tTrain Loss: 0.001917\n",
      "Train Epoch: 49 [4/19 (21%)]\tTrain Loss: 0.009518\n",
      "Train Epoch: 49 [8/19 (42%)]\tTrain Loss: 0.021597\n",
      "Train Epoch: 49 [12/19 (63%)]\tTrain Loss: 0.009355\n",
      "Train Epoch: 49 [16/19 (84%)]\tTrain Loss: 0.019364\n",
      "\n",
      "Train set: Average loss: 0.0550, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.34615384615384615\n",
      "\n",
      "Test set: Average loss: 0.0454, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 50 [0/19 (0%)]\tTrain Loss: 0.014617\n",
      "Train Epoch: 50 [4/19 (21%)]\tTrain Loss: 0.002632\n",
      "Train Epoch: 50 [8/19 (42%)]\tTrain Loss: 0.001370\n",
      "Train Epoch: 50 [12/19 (63%)]\tTrain Loss: 0.001566\n",
      "Train Epoch: 50 [16/19 (84%)]\tTrain Loss: 0.025288\n",
      "\n",
      "Train set: Average loss: 0.0472, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.4358974358974359\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 51 [0/19 (0%)]\tTrain Loss: 0.020864\n",
      "Train Epoch: 51 [4/19 (21%)]\tTrain Loss: 0.003354\n",
      "Train Epoch: 51 [8/19 (42%)]\tTrain Loss: 0.001074\n",
      "Train Epoch: 51 [12/19 (63%)]\tTrain Loss: 0.002049\n",
      "Train Epoch: 51 [16/19 (84%)]\tTrain Loss: 0.001429\n",
      "\n",
      "Train set: Average loss: 0.0114, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.2948717948717948\n",
      "\n",
      "Test set: Average loss: 0.0347, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 52 [0/19 (0%)]\tTrain Loss: 0.001807\n",
      "Train Epoch: 52 [4/19 (21%)]\tTrain Loss: 0.023927\n",
      "Train Epoch: 52 [8/19 (42%)]\tTrain Loss: 0.005742\n",
      "Train Epoch: 52 [12/19 (63%)]\tTrain Loss: 0.004912\n",
      "Train Epoch: 52 [16/19 (84%)]\tTrain Loss: 0.009840\n",
      "\n",
      "Train set: Average loss: 0.0105, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(4) tensor(3) tensor(1) tensor(0)\n",
      "tensor(8) tensor(3) tensor(1) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.16666666666666663\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 53 [0/19 (0%)]\tTrain Loss: 0.004432\n",
      "Train Epoch: 53 [4/19 (21%)]\tTrain Loss: 0.119826\n",
      "Train Epoch: 53 [8/19 (42%)]\tTrain Loss: 0.015809\n",
      "Train Epoch: 53 [12/19 (63%)]\tTrain Loss: 0.002063\n",
      "Train Epoch: 53 [16/19 (84%)]\tTrain Loss: 0.001093\n",
      "\n",
      "Train set: Average loss: 0.0180, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.43589743589743596\n",
      "\n",
      "Test set: Average loss: 0.0345, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 54 [0/19 (0%)]\tTrain Loss: 0.000721\n",
      "Train Epoch: 54 [4/19 (21%)]\tTrain Loss: 0.010938\n",
      "Train Epoch: 54 [8/19 (42%)]\tTrain Loss: 0.012475\n",
      "Train Epoch: 54 [12/19 (63%)]\tTrain Loss: 0.002245\n",
      "Train Epoch: 54 [16/19 (84%)]\tTrain Loss: 0.008563\n",
      "\n",
      "Train set: Average loss: 0.0180, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.4871794871794872\n",
      "\n",
      "Test set: Average loss: 0.0474, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 55 [0/19 (0%)]\tTrain Loss: 0.005514\n",
      "Train Epoch: 55 [4/19 (21%)]\tTrain Loss: 0.012085\n",
      "Train Epoch: 55 [8/19 (42%)]\tTrain Loss: 0.005646\n",
      "Train Epoch: 55 [12/19 (63%)]\tTrain Loss: 0.023239\n",
      "Train Epoch: 55 [16/19 (84%)]\tTrain Loss: 0.002620\n",
      "\n",
      "Train set: Average loss: 0.0233, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.7564102564102564\n",
      "\n",
      "Test set: Average loss: 0.0710, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 56 [0/19 (0%)]\tTrain Loss: 0.017163\n",
      "Train Epoch: 56 [4/19 (21%)]\tTrain Loss: 0.006218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [8/19 (42%)]\tTrain Loss: 0.009045\n",
      "Train Epoch: 56 [12/19 (63%)]\tTrain Loss: 0.015562\n",
      "Train Epoch: 56 [16/19 (84%)]\tTrain Loss: 0.017068\n",
      "\n",
      "Train set: Average loss: 0.0621, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.6923076923076923\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 57 [0/19 (0%)]\tTrain Loss: 0.001087\n",
      "Train Epoch: 57 [4/19 (21%)]\tTrain Loss: 0.017116\n",
      "Train Epoch: 57 [8/19 (42%)]\tTrain Loss: 0.052728\n",
      "Train Epoch: 57 [12/19 (63%)]\tTrain Loss: 0.040260\n",
      "Train Epoch: 57 [16/19 (84%)]\tTrain Loss: 0.005208\n",
      "\n",
      "Train set: Average loss: 0.0509, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.5256410256410257\n",
      "\n",
      "Test set: Average loss: 0.0746, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 58 [0/19 (0%)]\tTrain Loss: 0.038860\n",
      "Train Epoch: 58 [4/19 (21%)]\tTrain Loss: 0.013638\n",
      "Train Epoch: 58 [8/19 (42%)]\tTrain Loss: 0.003735\n",
      "Train Epoch: 58 [12/19 (63%)]\tTrain Loss: 0.005560\n",
      "Train Epoch: 58 [16/19 (84%)]\tTrain Loss: 0.046792\n",
      "\n",
      "Train set: Average loss: 0.0218, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(2) tensor(0) tensor(1) tensor(1)\n",
      "tensor(3) tensor(2) tensor(2) tensor(1)\n",
      "tensor(7) tensor(2) tensor(2) tensor(1)\n",
      "tensor(9) tensor(4) tensor(2) tensor(1)\n",
      "tensor(11) tensor(5) tensor(2) tensor(1)\n",
      "TP= tensor(11) TN= tensor(5) FN= tensor(2) FP= tensor(1)\n",
      "TP+FP tensor(12)\n",
      "precision 0.9166666666666666\n",
      "recall 0.8461538461538461\n",
      "F1 0.8799999999999999\n",
      "acc 0.8421052631578947\n",
      "AUC 0.2692307692307693\n",
      "\n",
      "Test set: Average loss: 0.0705, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 59 [0/19 (0%)]\tTrain Loss: 0.001335\n",
      "Train Epoch: 59 [4/19 (21%)]\tTrain Loss: 0.021158\n",
      "Train Epoch: 59 [8/19 (42%)]\tTrain Loss: 0.003294\n",
      "Train Epoch: 59 [12/19 (63%)]\tTrain Loss: 0.026021\n",
      "Train Epoch: 59 [16/19 (84%)]\tTrain Loss: 0.010650\n",
      "\n",
      "Train set: Average loss: 0.0168, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.2948717948717949\n",
      "\n",
      "Test set: Average loss: 0.0489, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 60 [0/19 (0%)]\tTrain Loss: 0.001594\n",
      "Train Epoch: 60 [4/19 (21%)]\tTrain Loss: 0.017878\n",
      "Train Epoch: 60 [8/19 (42%)]\tTrain Loss: 0.029475\n",
      "Train Epoch: 60 [12/19 (63%)]\tTrain Loss: 0.019516\n",
      "Train Epoch: 60 [16/19 (84%)]\tTrain Loss: 0.007553\n",
      "\n",
      "Train set: Average loss: 0.0606, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.21794871794871792\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 61 [0/19 (0%)]\tTrain Loss: 0.000796\n",
      "Train Epoch: 61 [4/19 (21%)]\tTrain Loss: 0.004543\n",
      "Train Epoch: 61 [8/19 (42%)]\tTrain Loss: 0.020238\n",
      "Train Epoch: 61 [12/19 (63%)]\tTrain Loss: 0.004201\n",
      "Train Epoch: 61 [16/19 (84%)]\tTrain Loss: 0.016844\n",
      "\n",
      "Train set: Average loss: 0.0130, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.2564102564102564\n",
      "\n",
      "Test set: Average loss: 0.0429, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 62 [0/19 (0%)]\tTrain Loss: 0.003083\n",
      "Train Epoch: 62 [4/19 (21%)]\tTrain Loss: 0.021919\n",
      "Train Epoch: 62 [8/19 (42%)]\tTrain Loss: 0.017986\n",
      "Train Epoch: 62 [12/19 (63%)]\tTrain Loss: 0.005712\n",
      "Train Epoch: 62 [16/19 (84%)]\tTrain Loss: 0.010756\n",
      "\n",
      "Train set: Average loss: 0.0109, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.3846153846153846\n",
      "\n",
      "Test set: Average loss: 0.0370, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 63 [0/19 (0%)]\tTrain Loss: 0.001852\n",
      "Train Epoch: 63 [4/19 (21%)]\tTrain Loss: 0.015052\n",
      "Train Epoch: 63 [8/19 (42%)]\tTrain Loss: 0.021111\n",
      "Train Epoch: 63 [12/19 (63%)]\tTrain Loss: 0.025721\n",
      "Train Epoch: 63 [16/19 (84%)]\tTrain Loss: 0.015021\n",
      "\n",
      "Train set: Average loss: 0.0084, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.5641025641025641\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 64 [0/19 (0%)]\tTrain Loss: 0.004161\n",
      "Train Epoch: 64 [4/19 (21%)]\tTrain Loss: 0.009686\n",
      "Train Epoch: 64 [8/19 (42%)]\tTrain Loss: 0.002716\n",
      "Train Epoch: 64 [12/19 (63%)]\tTrain Loss: 0.004225\n",
      "Train Epoch: 64 [16/19 (84%)]\tTrain Loss: 0.000625\n",
      "\n",
      "Train set: Average loss: 0.0072, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.5256410256410257\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 65 [0/19 (0%)]\tTrain Loss: 0.004169\n",
      "Train Epoch: 65 [4/19 (21%)]\tTrain Loss: 0.012999\n",
      "Train Epoch: 65 [8/19 (42%)]\tTrain Loss: 0.016069\n",
      "Train Epoch: 65 [12/19 (63%)]\tTrain Loss: 0.000418\n",
      "Train Epoch: 65 [16/19 (84%)]\tTrain Loss: 0.011283\n",
      "\n",
      "Train set: Average loss: 0.0530, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5897435897435898\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 66 [0/19 (0%)]\tTrain Loss: 0.002404\n",
      "Train Epoch: 66 [4/19 (21%)]\tTrain Loss: 0.000807\n",
      "Train Epoch: 66 [8/19 (42%)]\tTrain Loss: 0.008796\n",
      "Train Epoch: 66 [12/19 (63%)]\tTrain Loss: 0.002984\n",
      "Train Epoch: 66 [16/19 (84%)]\tTrain Loss: 0.003154\n",
      "\n",
      "Train set: Average loss: 0.0076, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.5384615384615385\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 67 [0/19 (0%)]\tTrain Loss: 0.001182\n",
      "Train Epoch: 67 [4/19 (21%)]\tTrain Loss: 0.005198\n",
      "Train Epoch: 67 [8/19 (42%)]\tTrain Loss: 0.018867\n",
      "Train Epoch: 67 [12/19 (63%)]\tTrain Loss: 0.010594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 67 [16/19 (84%)]\tTrain Loss: 0.013041\n",
      "\n",
      "Train set: Average loss: 0.0477, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.42307692307692313\n",
      "\n",
      "Test set: Average loss: 0.0298, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 68 [0/19 (0%)]\tTrain Loss: 0.001291\n",
      "Train Epoch: 68 [4/19 (21%)]\tTrain Loss: 0.000664\n",
      "Train Epoch: 68 [8/19 (42%)]\tTrain Loss: 0.001995\n",
      "Train Epoch: 68 [12/19 (63%)]\tTrain Loss: 0.002970\n",
      "Train Epoch: 68 [16/19 (84%)]\tTrain Loss: 0.030688\n",
      "\n",
      "Train set: Average loss: 0.0439, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.4871794871794872\n",
      "\n",
      "Test set: Average loss: 0.0313, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 69 [0/19 (0%)]\tTrain Loss: 0.001351\n",
      "Train Epoch: 69 [4/19 (21%)]\tTrain Loss: 0.001262\n",
      "Train Epoch: 69 [8/19 (42%)]\tTrain Loss: 0.005496\n",
      "Train Epoch: 69 [12/19 (63%)]\tTrain Loss: 0.008460\n",
      "Train Epoch: 69 [16/19 (84%)]\tTrain Loss: 0.041519\n",
      "\n",
      "Train set: Average loss: 0.0424, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.38461538461538464\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 70 [0/19 (0%)]\tTrain Loss: 0.001315\n",
      "Train Epoch: 70 [4/19 (21%)]\tTrain Loss: 0.002200\n",
      "Train Epoch: 70 [8/19 (42%)]\tTrain Loss: 0.247562\n",
      "Train Epoch: 70 [12/19 (63%)]\tTrain Loss: 0.005359\n",
      "Train Epoch: 70 [16/19 (84%)]\tTrain Loss: 0.002801\n",
      "\n",
      "Train set: Average loss: 0.0511, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(12) tensor(5) tensor(1) tensor(1)\n",
      "TP= tensor(12) TN= tensor(5) FN= tensor(1) FP= tensor(1)\n",
      "TP+FP tensor(13)\n",
      "precision 0.9230769230769231\n",
      "recall 0.9230769230769231\n",
      "F1 0.9230769230769231\n",
      "acc 0.8947368421052632\n",
      "AUC 0.3076923076923077\n",
      "\n",
      "Test set: Average loss: 0.0680, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 71 [0/19 (0%)]\tTrain Loss: 0.013005\n",
      "Train Epoch: 71 [4/19 (21%)]\tTrain Loss: 0.022849\n",
      "Train Epoch: 71 [8/19 (42%)]\tTrain Loss: 0.022509\n",
      "Train Epoch: 71 [12/19 (63%)]\tTrain Loss: 0.004581\n",
      "Train Epoch: 71 [16/19 (84%)]\tTrain Loss: 0.003750\n",
      "\n",
      "Train set: Average loss: 0.0152, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.7051282051282052\n",
      "\n",
      "Test set: Average loss: 0.0353, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 72 [0/19 (0%)]\tTrain Loss: 0.025072\n",
      "Train Epoch: 72 [4/19 (21%)]\tTrain Loss: 0.035856\n",
      "Train Epoch: 72 [8/19 (42%)]\tTrain Loss: 0.006957\n",
      "Train Epoch: 72 [12/19 (63%)]\tTrain Loss: 0.003871\n",
      "Train Epoch: 72 [16/19 (84%)]\tTrain Loss: 0.003265\n",
      "\n",
      "Train set: Average loss: 0.0188, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5\n",
      "\n",
      "Test set: Average loss: 0.0422, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 73 [0/19 (0%)]\tTrain Loss: 0.003244\n",
      "Train Epoch: 73 [4/19 (21%)]\tTrain Loss: 0.026614\n",
      "Train Epoch: 73 [8/19 (42%)]\tTrain Loss: 0.003845\n",
      "Train Epoch: 73 [12/19 (63%)]\tTrain Loss: 0.015867\n",
      "Train Epoch: 73 [16/19 (84%)]\tTrain Loss: 0.003091\n",
      "\n",
      "Train set: Average loss: 0.0129, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.7692307692307692\n",
      "\n",
      "Test set: Average loss: 0.0388, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 74 [0/19 (0%)]\tTrain Loss: 0.003839\n",
      "Train Epoch: 74 [4/19 (21%)]\tTrain Loss: 0.013208\n",
      "Train Epoch: 74 [8/19 (42%)]\tTrain Loss: 0.017000\n",
      "Train Epoch: 74 [12/19 (63%)]\tTrain Loss: 0.012170\n",
      "Train Epoch: 74 [16/19 (84%)]\tTrain Loss: 0.002292\n",
      "\n",
      "Train set: Average loss: 0.0105, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5641025641025641\n",
      "\n",
      "Test set: Average loss: 0.0485, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 75 [0/19 (0%)]\tTrain Loss: 0.012509\n",
      "Train Epoch: 75 [4/19 (21%)]\tTrain Loss: 0.057641\n",
      "Train Epoch: 75 [8/19 (42%)]\tTrain Loss: 0.005025\n",
      "Train Epoch: 75 [12/19 (63%)]\tTrain Loss: 0.001730\n",
      "Train Epoch: 75 [16/19 (84%)]\tTrain Loss: 0.015589\n",
      "\n",
      "Train set: Average loss: 0.0096, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5897435897435899\n",
      "\n",
      "Test set: Average loss: 0.0348, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 76 [0/19 (0%)]\tTrain Loss: 0.009548\n",
      "Train Epoch: 76 [4/19 (21%)]\tTrain Loss: 0.001806\n",
      "Train Epoch: 76 [8/19 (42%)]\tTrain Loss: 0.009993\n",
      "Train Epoch: 76 [12/19 (63%)]\tTrain Loss: 0.010847\n",
      "Train Epoch: 76 [16/19 (84%)]\tTrain Loss: 0.000709\n",
      "\n",
      "Train set: Average loss: 0.0412, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.6025641025641026\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 77 [0/19 (0%)]\tTrain Loss: 0.009857\n",
      "Train Epoch: 77 [4/19 (21%)]\tTrain Loss: 0.001071\n",
      "Train Epoch: 77 [8/19 (42%)]\tTrain Loss: 0.001514\n",
      "Train Epoch: 77 [12/19 (63%)]\tTrain Loss: 0.001424\n",
      "Train Epoch: 77 [16/19 (84%)]\tTrain Loss: 0.001435\n",
      "\n",
      "Train set: Average loss: 0.0064, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(11) tensor(5) tensor(2) tensor(1)\n",
      "TP= tensor(11) TN= tensor(5) FN= tensor(2) FP= tensor(1)\n",
      "TP+FP tensor(12)\n",
      "precision 0.9166666666666666\n",
      "recall 0.8461538461538461\n",
      "F1 0.8799999999999999\n",
      "acc 0.8421052631578947\n",
      "AUC 0.44871794871794873\n",
      "\n",
      "Test set: Average loss: 0.0452, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 78 [0/19 (0%)]\tTrain Loss: 0.024606\n",
      "Train Epoch: 78 [4/19 (21%)]\tTrain Loss: 0.003046\n",
      "Train Epoch: 78 [8/19 (42%)]\tTrain Loss: 0.014644\n",
      "Train Epoch: 78 [12/19 (63%)]\tTrain Loss: 0.000594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 78 [16/19 (84%)]\tTrain Loss: 0.001663\n",
      "\n",
      "Train set: Average loss: 0.0078, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.5641025641025641\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 79 [0/19 (0%)]\tTrain Loss: 0.000618\n",
      "Train Epoch: 79 [4/19 (21%)]\tTrain Loss: 0.006224\n",
      "Train Epoch: 79 [8/19 (42%)]\tTrain Loss: 0.019495\n",
      "Train Epoch: 79 [12/19 (63%)]\tTrain Loss: 0.007252\n",
      "Train Epoch: 79 [16/19 (84%)]\tTrain Loss: 0.012098\n",
      "\n",
      "Train set: Average loss: 0.0075, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.4102564102564103\n",
      "\n",
      "Test set: Average loss: 0.0240, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 80 [0/19 (0%)]\tTrain Loss: 0.009387\n",
      "Train Epoch: 80 [4/19 (21%)]\tTrain Loss: 0.002833\n",
      "Train Epoch: 80 [8/19 (42%)]\tTrain Loss: 0.000419\n",
      "Train Epoch: 80 [12/19 (63%)]\tTrain Loss: 0.007057\n",
      "Train Epoch: 80 [16/19 (84%)]\tTrain Loss: 0.005235\n",
      "\n",
      "Train set: Average loss: 0.0039, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.4615384615384616\n",
      "\n",
      "Test set: Average loss: 0.0303, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 81 [0/19 (0%)]\tTrain Loss: 0.000345\n",
      "Train Epoch: 81 [4/19 (21%)]\tTrain Loss: 0.005052\n",
      "Train Epoch: 81 [8/19 (42%)]\tTrain Loss: 0.005627\n",
      "Train Epoch: 81 [12/19 (63%)]\tTrain Loss: 0.014959\n",
      "Train Epoch: 81 [16/19 (84%)]\tTrain Loss: 0.003102\n",
      "\n",
      "Train set: Average loss: 0.0040, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.4487179487179488\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 82 [0/19 (0%)]\tTrain Loss: 0.001610\n",
      "Train Epoch: 82 [4/19 (21%)]\tTrain Loss: 0.000601\n",
      "Train Epoch: 82 [8/19 (42%)]\tTrain Loss: 0.000489\n",
      "Train Epoch: 82 [12/19 (63%)]\tTrain Loss: 0.003108\n",
      "Train Epoch: 82 [16/19 (84%)]\tTrain Loss: 0.000927\n",
      "\n",
      "Train set: Average loss: 0.0033, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.5128205128205129\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 83 [0/19 (0%)]\tTrain Loss: 0.000681\n",
      "Train Epoch: 83 [4/19 (21%)]\tTrain Loss: 0.000634\n",
      "Train Epoch: 83 [8/19 (42%)]\tTrain Loss: 0.002294\n",
      "Train Epoch: 83 [12/19 (63%)]\tTrain Loss: 0.001408\n",
      "Train Epoch: 83 [16/19 (84%)]\tTrain Loss: 0.004817\n",
      "\n",
      "Train set: Average loss: 0.0023, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.5128205128205129\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 84 [0/19 (0%)]\tTrain Loss: 0.001187\n",
      "Train Epoch: 84 [4/19 (21%)]\tTrain Loss: 0.005169\n",
      "Train Epoch: 84 [8/19 (42%)]\tTrain Loss: 0.004503\n",
      "Train Epoch: 84 [12/19 (63%)]\tTrain Loss: 0.002542\n",
      "Train Epoch: 84 [16/19 (84%)]\tTrain Loss: 0.005695\n",
      "\n",
      "Train set: Average loss: 0.0037, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.6153846153846154\n",
      "\n",
      "Test set: Average loss: 0.0405, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 85 [0/19 (0%)]\tTrain Loss: 0.007960\n",
      "Train Epoch: 85 [4/19 (21%)]\tTrain Loss: 0.003852\n",
      "Train Epoch: 85 [8/19 (42%)]\tTrain Loss: 0.008688\n",
      "Train Epoch: 85 [12/19 (63%)]\tTrain Loss: 0.004229\n",
      "Train Epoch: 85 [16/19 (84%)]\tTrain Loss: 0.000395\n",
      "\n",
      "Train set: Average loss: 0.0038, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.7307692307692308\n",
      "\n",
      "Test set: Average loss: 0.0446, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 86 [0/19 (0%)]\tTrain Loss: 0.002266\n",
      "Train Epoch: 86 [4/19 (21%)]\tTrain Loss: 0.003826\n",
      "Train Epoch: 86 [8/19 (42%)]\tTrain Loss: 0.008537\n",
      "Train Epoch: 86 [12/19 (63%)]\tTrain Loss: 0.000320\n",
      "Train Epoch: 86 [16/19 (84%)]\tTrain Loss: 0.004075\n",
      "\n",
      "Train set: Average loss: 0.0501, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.7051282051282052\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 87 [0/19 (0%)]\tTrain Loss: 0.003801\n",
      "Train Epoch: 87 [4/19 (21%)]\tTrain Loss: 0.003168\n",
      "Train Epoch: 87 [8/19 (42%)]\tTrain Loss: 0.000211\n",
      "Train Epoch: 87 [12/19 (63%)]\tTrain Loss: 0.000632\n",
      "Train Epoch: 87 [16/19 (84%)]\tTrain Loss: 0.000322\n",
      "\n",
      "Train set: Average loss: 0.0042, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.39743589743589747\n",
      "\n",
      "Test set: Average loss: 0.0346, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 88 [0/19 (0%)]\tTrain Loss: 0.000906\n",
      "Train Epoch: 88 [4/19 (21%)]\tTrain Loss: 0.001646\n",
      "Train Epoch: 88 [8/19 (42%)]\tTrain Loss: 0.006223\n",
      "Train Epoch: 88 [12/19 (63%)]\tTrain Loss: 0.000287\n",
      "Train Epoch: 88 [16/19 (84%)]\tTrain Loss: 0.006702\n",
      "\n",
      "Train set: Average loss: 0.0039, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.4743589743589744\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 89 [0/19 (0%)]\tTrain Loss: 0.011339\n",
      "Train Epoch: 89 [4/19 (21%)]\tTrain Loss: 0.000437\n",
      "Train Epoch: 89 [8/19 (42%)]\tTrain Loss: 0.001658\n",
      "Train Epoch: 89 [12/19 (63%)]\tTrain Loss: 0.006487\n",
      "Train Epoch: 89 [16/19 (84%)]\tTrain Loss: 0.000522\n",
      "\n",
      "Train set: Average loss: 0.0060, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.4615384615384616\n",
      "\n",
      "Test set: Average loss: 0.0240, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 90 [0/19 (0%)]\tTrain Loss: 0.000516\n",
      "Train Epoch: 90 [4/19 (21%)]\tTrain Loss: 0.007712\n",
      "Train Epoch: 90 [8/19 (42%)]\tTrain Loss: 0.000437\n",
      "Train Epoch: 90 [12/19 (63%)]\tTrain Loss: 0.000571\n",
      "Train Epoch: 90 [16/19 (84%)]\tTrain Loss: 0.004769\n",
      "\n",
      "Train set: Average loss: 0.0446, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5256410256410258\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 91 [0/19 (0%)]\tTrain Loss: 0.011261\n",
      "Train Epoch: 91 [4/19 (21%)]\tTrain Loss: 0.000451\n",
      "Train Epoch: 91 [8/19 (42%)]\tTrain Loss: 0.000670\n",
      "Train Epoch: 91 [12/19 (63%)]\tTrain Loss: 0.000984\n",
      "Train Epoch: 91 [16/19 (84%)]\tTrain Loss: 0.000521\n",
      "\n",
      "Train set: Average loss: 0.0043, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.4743589743589744\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 92 [0/19 (0%)]\tTrain Loss: 0.007713\n",
      "Train Epoch: 92 [4/19 (21%)]\tTrain Loss: 0.000348\n",
      "Train Epoch: 92 [8/19 (42%)]\tTrain Loss: 0.000520\n",
      "Train Epoch: 92 [12/19 (63%)]\tTrain Loss: 0.002203\n",
      "Train Epoch: 92 [16/19 (84%)]\tTrain Loss: 0.000920\n",
      "\n",
      "Train set: Average loss: 0.0042, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.6666666666666666\n",
      "\n",
      "Test set: Average loss: 0.0683, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 93 [0/19 (0%)]\tTrain Loss: 0.005357\n",
      "Train Epoch: 93 [4/19 (21%)]\tTrain Loss: 0.001560\n",
      "Train Epoch: 93 [8/19 (42%)]\tTrain Loss: 0.018390\n",
      "Train Epoch: 93 [12/19 (63%)]\tTrain Loss: 0.001212\n",
      "Train Epoch: 93 [16/19 (84%)]\tTrain Loss: 0.006322\n",
      "\n",
      "Train set: Average loss: 0.0053, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.4871794871794872\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 94 [0/19 (0%)]\tTrain Loss: 0.001012\n",
      "Train Epoch: 94 [4/19 (21%)]\tTrain Loss: 0.000875\n",
      "Train Epoch: 94 [8/19 (42%)]\tTrain Loss: 0.000370\n",
      "Train Epoch: 94 [12/19 (63%)]\tTrain Loss: 0.000285\n",
      "Train Epoch: 94 [16/19 (84%)]\tTrain Loss: 0.006697\n",
      "\n",
      "Train set: Average loss: 0.0035, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(5) tensor(0) tensor(0)\n",
      "tensor(13) tensor(6) tensor(0) tensor(0)\n",
      "TP= tensor(13) TN= tensor(6) FN= tensor(0) FP= tensor(0)\n",
      "TP+FP tensor(13)\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUC 0.4871794871794872\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 19/19 (100%)\n",
      "\n",
      "Train Epoch: 95 [0/19 (0%)]\tTrain Loss: 0.008065\n",
      "Train Epoch: 95 [4/19 (21%)]\tTrain Loss: 0.008800\n",
      "Train Epoch: 95 [8/19 (42%)]\tTrain Loss: 0.008944\n",
      "Train Epoch: 95 [12/19 (63%)]\tTrain Loss: 0.000462\n",
      "Train Epoch: 95 [16/19 (84%)]\tTrain Loss: 0.004439\n",
      "\n",
      "Train set: Average loss: 0.0063, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n",
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.6923076923076923\n",
      "\n",
      "Test set: Average loss: 0.0309, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 96 [0/19 (0%)]\tTrain Loss: 0.018030\n",
      "Train Epoch: 96 [4/19 (21%)]\tTrain Loss: 0.008085\n",
      "Train Epoch: 96 [8/19 (42%)]\tTrain Loss: 0.001220\n",
      "Train Epoch: 96 [12/19 (63%)]\tTrain Loss: 0.004104\n",
      "Train Epoch: 96 [16/19 (84%)]\tTrain Loss: 0.000849\n",
      "\n",
      "Train set: Average loss: 0.0062, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(4) tensor(2) tensor(1) tensor(1)\n",
      "tensor(8) tensor(2) tensor(1) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(11) tensor(5) tensor(2) tensor(1)\n",
      "TP= tensor(11) TN= tensor(5) FN= tensor(2) FP= tensor(1)\n",
      "TP+FP tensor(12)\n",
      "precision 0.9166666666666666\n",
      "recall 0.8461538461538461\n",
      "F1 0.8799999999999999\n",
      "acc 0.8421052631578947\n",
      "AUC 0.48717948717948717\n",
      "\n",
      "Test set: Average loss: 0.1511, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 97 [0/19 (0%)]\tTrain Loss: 0.000669\n",
      "Train Epoch: 97 [4/19 (21%)]\tTrain Loss: 0.000746\n",
      "Train Epoch: 97 [8/19 (42%)]\tTrain Loss: 0.005721\n",
      "Train Epoch: 97 [12/19 (63%)]\tTrain Loss: 0.003935\n",
      "Train Epoch: 97 [16/19 (84%)]\tTrain Loss: 0.019309\n",
      "\n",
      "Train set: Average loss: 0.0195, Accuracy: 71/73 (97%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(2) tensor(0) tensor(1)\n",
      "tensor(9) tensor(2) tensor(0) tensor(1)\n",
      "tensor(10) tensor(4) tensor(1) tensor(1)\n",
      "tensor(11) tensor(5) tensor(2) tensor(1)\n",
      "TP= tensor(11) TN= tensor(5) FN= tensor(2) FP= tensor(1)\n",
      "TP+FP tensor(12)\n",
      "precision 0.9166666666666666\n",
      "recall 0.8461538461538461\n",
      "F1 0.8799999999999999\n",
      "acc 0.8421052631578947\n",
      "AUC 0.5897435897435899\n",
      "\n",
      "Test set: Average loss: 0.0815, Accuracy: 16/19 (84%)\n",
      "\n",
      "Train Epoch: 98 [0/19 (0%)]\tTrain Loss: 0.011635\n",
      "Train Epoch: 98 [4/19 (21%)]\tTrain Loss: 0.008478\n",
      "Train Epoch: 98 [8/19 (42%)]\tTrain Loss: 0.004013\n",
      "Train Epoch: 98 [12/19 (63%)]\tTrain Loss: 0.106061\n",
      "Train Epoch: 98 [16/19 (84%)]\tTrain Loss: 0.028918\n",
      "\n",
      "Train set: Average loss: 0.0143, Accuracy: 72/73 (99%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(10) tensor(5) tensor(1) tensor(0)\n",
      "tensor(12) tensor(6) tensor(1) tensor(0)\n",
      "TP= tensor(12) TN= tensor(6) FN= tensor(1) FP= tensor(0)\n",
      "TP+FP tensor(12)\n",
      "precision 1.0\n",
      "recall 0.9230769230769231\n",
      "F1 0.9600000000000001\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5384615384615385\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 18/19 (95%)\n",
      "\n",
      "Train Epoch: 99 [0/19 (0%)]\tTrain Loss: 0.003206\n",
      "Train Epoch: 99 [4/19 (21%)]\tTrain Loss: 0.017192\n",
      "Train Epoch: 99 [8/19 (42%)]\tTrain Loss: 0.024299\n",
      "Train Epoch: 99 [12/19 (63%)]\tTrain Loss: 0.027428\n",
      "Train Epoch: 99 [16/19 (84%)]\tTrain Loss: 0.008368\n",
      "\n",
      "Train set: Average loss: 0.0098, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(0) tensor(0) tensor(1)\n",
      "tensor(5) tensor(1) tensor(0) tensor(2)\n",
      "tensor(9) tensor(1) tensor(0) tensor(2)\n",
      "tensor(11) tensor(3) tensor(0) tensor(2)\n",
      "tensor(13) tensor(4) tensor(0) tensor(2)\n",
      "TP= tensor(13) TN= tensor(4) FN= tensor(0) FP= tensor(2)\n",
      "TP+FP tensor(15)\n",
      "precision 0.8666666666666667\n",
      "recall 1.0\n",
      "F1 0.9285714285714286\n",
      "acc 0.8947368421052632\n",
      "AUC 0.2564102564102564\n",
      "\n",
      "Test set: Average loss: 0.1351, Accuracy: 17/19 (89%)\n",
      "\n",
      "Train Epoch: 100 [0/19 (0%)]\tTrain Loss: 0.030155\n",
      "Train Epoch: 100 [4/19 (21%)]\tTrain Loss: 0.000713\n",
      "Train Epoch: 100 [8/19 (42%)]\tTrain Loss: 0.001144\n",
      "Train Epoch: 100 [12/19 (63%)]\tTrain Loss: 0.002213\n",
      "Train Epoch: 100 [16/19 (84%)]\tTrain Loss: 0.000681\n",
      "\n",
      "Train set: Average loss: 0.0071, Accuracy: 73/73 (100%)\n",
      "\n",
      "tensor(3) tensor(1) tensor(0) tensor(0)\n",
      "tensor(5) tensor(3) tensor(0) tensor(0)\n",
      "tensor(9) tensor(3) tensor(0) tensor(0)\n",
      "tensor(11) tensor(4) tensor(0) tensor(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13) tensor(5) tensor(0) tensor(1)\n",
      "TP= tensor(13) TN= tensor(5) FN= tensor(0) FP= tensor(1)\n",
      "TP+FP tensor(14)\n",
      "precision 0.9285714285714286\n",
      "recall 1.0\n",
      "F1 0.962962962962963\n",
      "acc 0.9473684210526315\n",
      "AUC 0.5256410256410257\n",
      "\n",
      "Test set: Average loss: 0.0376, Accuracy: 18/19 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "for epoch in range(1, 100+1):\n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    test(epoch)\n",
    "\n",
    "    # Save model\n",
    "#     torch.save(model.state_dict(), \"model_backup/AlexNet_3_class_xray_cnn_{}.pt\".format(epoch))  \n",
    "\n",
    "\n",
    "# state = {'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "#                  'optimizer': optimizer.state_dict(), 'scheduler' : scheduler}\n",
    "# torch.save(state, \"model_backup/AlexNetAdamState\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
